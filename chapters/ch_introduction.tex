\chapter{Introduction}


Quantum computing has the potential to transcend the information technology as we know it. Small scale quantum systems are already possible today and the goal is to scale up these quantum architectures to build practical quantum devices. One approach to do this is to by networking many simple processor cells together through quantum links, avoiding the necessity to build a single complex structure. Processor cells that are located physically close to each other are connected by ``short'' links and lie in a patch. Patches that are located physically far from each other can in turn be connected by ``long'' links, such as remote optical connections. The total state of system, which contains the stored information, is shared across these patches, such that it can be accessed in either one of these patches. \\

This is somewhat analogous to the idea of a shared database. Many online services that we use today rely on servers that host the data that we want to view, store or edit. This data is often not stored on a single server, but copied to many others, in a shared database. In case one of these servers goes offline due to file corruption or an electricity outrage, the data is not lost, and can still be accessed on another server in the cluster.\\

In our Quantum network, information cannot be copied across different processor cells due to the no cloning theorem. In stead, it is shared across cells through entanglement. A cell can also go ``offline", when a qubit or multiple qubits are lost from the system due to some interaction with the environment. This process is called decoherence, also described with \emph{loss} or \emph{erasure}. Luckily, if the losses are not too much, these cells can be restored through quantum error correction (QEC) such that the quantum state or encoded information can still be extracted from the system. \\

\subsection{Quantum errors}
Errors that can occur during Quantum computation can generally be classified as 1) noise, in which there is an error are within the computational basis, or as 2) a loss, in which the qubit is
taken out of the computational basis. Losses are both detectable and locatable, which means that a higher rate of loss ($p_{loss}$) can be tolerated than noise or computational errors ($p_{com}$). The process of finding and correcting these errors is called decoding. \\

Kitaev's surfaces codes are defined by a set of stabilizers which act on a set of physical qubits that lie on the edges of a square lattice \cite{dennis2002topological}. The stabilizers commute, and are generated by plaquettes (group of $Z$ operators), or by stars (group of $X$ operators). Logical operates corresponds to a set of stabilizer operators along a homologically nontrivial cycle. Any homologically equivalent set of operators can be used to measure the physical qubit operator. Therefore, in the case of a qubit loss, another set of operators can be used, if there is no \emph{percolated} region of losses that span the entire lattice. \\

To decode for computational errors, one measures the stabilizer generators, which returns eigenvalue -1 on the edges of the error chains or syndromes, and can be corrected by finding a nontrivial closing chain, which either equals a stabilizer measurement that corrects the error, or a logical operator which equals a logical error. This problem is equivalent to the two dimensional random-bond Ising model (RBIM), where the shortest path needs to be found between matching pairs. The closing chain is found using the Edmonds' minimum weight perfect matching (MWPM) algorithm. This algorithm scales quadratic in time as the lattice size increases \cite{stace2009thresholds}. More recently, an almost-linear decoding approach has been described by Delfosse et al. \cite{delfosse2017linear}. \\

There are also multiple methods to decode for losses on the surface code. Stace et. al \cite{stace2009thresholds,stace2010error} describes the method of so-called superplaquettes and superstars, in which the lost qubit is accounted for by combining neighboring stabilizers. The resulting lattice can be than decoded using the same MWPM algorithm. Delfosse et al \cite{delfosse2017linear} describes a linear-time maximum likelihood method to decode for losses. Here, the errors are found in a \emph{peeling} algorithm that iteratively peels branches away from a tree of possible error chains until the lost qubits remain.

The Union-Find decoder is preferred over other types of decoders because it is \emph{simple}. Even though it may not seem so due to the length of its chapter, the concept of the Union-Find decoder is much more straightforward compared with other, more advanced decoders. 


Chapters \ref{ch:qec} up until Chapter \ref{ch:UFdecoder} Section \ref{sec:bucketwg} are descriptions of existing and known material. Section \ref{sec:bucketwg} and onwards includes exclusively our own contributions. 