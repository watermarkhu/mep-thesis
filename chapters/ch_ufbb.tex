\chapter{Union-Find Balanced-Bloom decoder}\label{ch:ufbb}

\tikzstyle{node}=[circle, draw=black, minimum size=25pt, line width=1, inner sep= 5pt]
\tikzstyle{nodel}=[circle, draw=black, minimum size=15pt, line width=1, inner sep= 0pt]
\tikzstyle{node1}=[circle, draw=black, minimum size=15pt, line width=1, inner sep= 2pt]
\tikzstyle{node2}=[circle, draw=black, minimum size=8pt, line width=1, inner sep= 0pt, fill=white!70!black]
\tikzstyle{l1}=[line width=1]
\tikzfading[name=fade right, left color=transparent!0, right color=transparent!100]
\tikzstyle{odd}=[node1, dashed, pattern=dots, pattern color=mred!75!white]
\tikzstyle{even}=[node1, pattern=dots, pattern color=mblue!75!white]
\tikzstyle{lodd}=[odd, pattern = crosshatch dots]
\tikzstyle{leven}=[even, pattern = crosshatch dots]
\tikzstyle{enset}=[node1, thick, double, font=\footnotesize]
\tikzstyle{onset}=[node1, thick, densely dashed, double, font=\footnotesize]
\tikzstyle{subtree}=[node1, opacity=0.3,dotted, font=\footnotesize]

% Recall that in the Union-Find decoder, each cluster represented by a set of vertices $C_i = |\{v_1, v_2, ...\}$ stored as a disjoint-set tree of the Union-Find data structure. To find the parent cluster of any given vertex, we follow subsequent parent pointers to the root vertex of the tree, which is the representative element of the cluster. Merges between clusters is done by simply pointing the root of one tree to another. By implementing additional rules \emph{path compression} and either \emph{union by weight} or \emph{union by rank}, the heights of the trees are dynamically kept low, such that the overall complexity of the algorithm for a system of $n$ qubits is $n\alpha(n)$, where $\alpha(n)\leq 4$ for all physical values of $n$. 

In this chapter we describe a modification of the UF-decoder, dubbed the \emph{Union-Find Balanced-Bloom} decoder, that increases the code threshold of the UF-decoder by improving its heuristic for minimum-weight matchings. We show that the modified decoder retains a relatively low time-complexity. 

Within the vanilla UF-decoder, not all odd-parity clusters are grown at the same time. Larger clusters relatively add more "incorrect edges" to themselves than compared to a smaller cluster (lemma \ref{lem:incorrectedges}). The UF decoder therefore applies \emph{weighted growth} of clusters, where the order of cluster growth is sorted based on the cluster sizes. We have shown a linear time implementation utilizing \emph{bucket sort} in Section \ref{sec:bucketwg}. With the addition of weighted growth, the error threshold of the UF decoder is reported to increase from $9.2\%$ to $9.9\%$ for a 2D toric lattice \cite{delfosse2017almost}, whereas we measured an increase from $9.716\%$ to $9.984\%$ in our implementation of the decoder (Section \ref{sec:ufperformance}). Furthermore, we showed that by always maintaining a dynamic forest where all clusters are connected acyclic graphs (Section \ref{sec:dynamicforest}), a slight increase in the code threshold and reduced running time can be obtained. 

From the simulated results of several of our implementations of the Union-Find decoder (Section \ref{sec:ufimplementations}), we grew the intuition that a decreased weight is to some extend a heuristic for an increased code threshold (formalized in Proposition \ref{prop:mw2}). In fact, the instruction of the Union-Find decoder mostly tries to obtain a low weight matching; by growing the odd-parity clusters on their boundaries a single layer at the time, unions between odd-parity clusters mostly occur on nearest neighbors. The discrete coordinates of the lattice limits the number of growth iterations to a constant proportional to the lattice. But also due to this discreteness, there may be many unions within each growth iteration, and nearest-neighbor unions between clusters may not result in a minimum-weight matching between syndromes. Especially as the clusters increase in size, also does their boundaries, and a increasingly larger amount of "incorrect edges" are added to the cluster. Weighted grow reduces the number of large-cluster growths, but does not decrease the number of "incorrect edges" if a large cluster is grown. This leaves us with the question: Should all boundary edges of a cluster be grown simultaneously?

% A large cluster is generally the result of multiple rounds of growth of a smaller cluster. Each iteration of cluster growth buries the syndromes within that cluster with a layer of edges, of which only a small portion will be part of the matching, where each layer adds to the matching weight. With weighted growth, smaller clusters are grown first, such that this effect is less dominant. But the UF decoder is unsurprisingly less successful at minimum-weight than the MWPM decoder, which does this perfectly. The MWPM decoder considers all possible matchings by constructing a fully connected graph where the edges have the distance between syndrome as weights. The UF decoder does not look at the lattice in such a global way, but performs locally on each cluster. This should yield the same result conceptually, but in reality it does not due to a major weakness; In each round of growth, all boundary edges are grown simultaneously. The potential union of two clusters is reserved to one edge but may occur on many, is only handled after each round, where the order of the merging edges determines which edge is selected as the bridge.
We suspect that the error threshold of the Union-Find decoder can be increased by improving the heuristic for minimum-weight matchings. In this chapter, we accomplish this by sorting the growth of specific subsets ofa cluster according to a parameter that we dub the \emph{potential matching weight}, explained in \ref{sec:PMW}. We introduce a new data structure that we call the \emph{node-tree} of a cluster in \ref{sec:nodeset}. Within this node-tree, we compute the node \emph{parity} and \emph{delay} in \ref{sec:nodedelay} and \ref{sec:bbstate}, which sets the order of boundary edge growth. In \ref{sec:growingcluster} through \ref{sec:nodejoin}, we cover the rules for growth and join operations for the node-trees, which are more complex than those of the UF algorithm. The modified decoder, the Union-Find Balanced-Bloom decoder, still has a relatively low worst-case quasilinaer time complexity, which is approximated in \ref{sec:ufbbcomplexity}. 

\section{A potential matching weight}\label{sec:PMW}

The Minimum-Weight Perfect Matching decoder finds the minimum-weight subset of edges by constructing a fully connected graph between all vertices (Section \ref{sec:MWPMdecoder}). By computing on the entire lattice, we denote such decoder as a \emph{global} decoder. The Union-Find decoder is a \emph{local} decoder, as each cluster is grown individually, oblivious about its surrounding neighbors until it merges into them. We introduce in this section the concept of a \emph{potential matching weight} of an odd-parity cluster, and we show that its value is not constant across the vertices of a cluster. Recall from Definition \ref{def:cluster} that a cluster with index $i$ is defined as a object $c_i$ with an edge set $\m{E}_i$ and vertex-tree $\m{V}_i$.

\begin{definition}\label{def:pmw}
  Consider an odd-parity cluster $c_i$ containing a vertex $v$. The Potential Matching Weight (PMW) of the vertex $v$ is the matching weight in the subset of edges of an odd-parity cluster $c_i$ in a hypothetical union with another cluster $c_j$ in the next growth iteration, where the merging boundary edge is supported by $v$. 
  \begin{equation}
    PMW(v) = \abs{\m{C} \cap \m{E}_{i}} + 1 \text{ if } c_i, c_j \text{ merged by } \codefunc{Union}(v,u) | v \in \delta\m{V}_{i}, u \in \delta\m{V}_{j}, 
  \end{equation}
  In other words, the potential matching weight is a vertex-specific predictive heuristic to the matching weight assuming an union in the next growth iteration. 
\end{definition}

Note that the potential matching weight is thus not defined for a vertex that is not in the boundary of a cluster. Let us first consider an example. Cluster $c_e$ is defined by vertex-tree $\vset_e = \{v_1, v_2, v_3\}$, where each vertex is a syndrome-vertex $\vset_e \subset \sigma$ (Figure \ref{fig:PMW}). The vertices lie on a horizontal line, distance 1 from each other, where each vertex has grown a single iteration of half-edges. The cluster has odd parity and is queued for growth. Let us investigate the weights of a matching if an additional vertex $v_o$ is connected to the cluster. If $v_o$ is connected to $v_1$ or to $v_3$, then the resulting matchings have a total weight of 2: $\{(v_o,v_1), (v_2,v_3)\}$ or $\{(v_o,v_3),(v_1,v_2)\}$, respectively. However if $v_o$ is connected to vertex $v_2$, then the total weight is 3: $\{(v_o, v_2),(v_1, v_3)\}$, where $(v_1,v_3)$ has weight 2. 

From the above example, we can see that even for a minimal size odd cluster that is not a single vertex, the PMW is not equal for all vertices in the cluster. It would therefore not be optimal to grow all boundary edges simultaneously, as boundaries connected to vertices with a high PNW potentially result in a higher matching weight. The growth these high PMV boundaries should thus be delayed for some iterations. When the PMV across the cluster reach an equilibrium, there is no benefit of growing some boundaries before others, and simultaneous growth is allowed again.

\input{tikzfigs/potentialmatchingweight.tex}

However, the calculation of the PMW is seemingly not as straight forward, especially for clusters if increasingly larger size. Furthermore, if the PMW is to be calculated for every vertex with boundary edges in all clusters in every growth iteration, the time complexity of the algorithm would increase dramatically. Luckily, we can reduce these calculations to be performed on a set of \emph{nodes} in each cluster, which we clarify in the next section.

\section{node-tree data structure of clusters}\label{sec:nodeset}

To efficiently calculate the potential matching weights in a cluster, we introduce here an additional data structure, the \emph{node-tree} of a cluster, that coexists with the Union-Find data structure. We consider the case of independent noise, after syndrome identification, all identified clusters consist of a single syndrome-vertex $v_\sigma \in \sigma$. Note that with erasure noise, the initial identified clusters may be of larger size, where each connected graph of erased edges belonging to the same cluster. This set of clusters is equivalent to the syndrome set $\sigma$. Within syndrome validation, these clusters are subjected to growth and merge events with other clusters. During growth, all vertices that are added to some cluster $c_j$ have a closest syndrome $\sigma$ within $c_j$ that is in the syndrome set $\sigma$, if a dynamic tree of the cluster is maintained. Recall from section \ref{sec:dynamicforest} that a such a cluster always is a connected acyclic graph. Even after cluster merges, newly added vertices have some closely located syndrome-vertex. The growth of a clusters can thus be interpreted to be \emph{seeded} in the syndrome vertices $v_\sigma \in \sigma$, thus the growth of a single cluster containing multiple syndrome vertices is related to multiple seeded growths. 

\begin{theorem}\label{the:nodepmw}
  All vertices in the subset of boundary vertices seeded in the same syndrome-vertex $ \{v_1, v_2,...\}_{v_\sigma}$ have the same potential matching weight, if a dynamic forest is maintained. 
\end{theorem}
\begin{proof}
  All vertices $v_i \in \{v_1, v_2,...\}_{v_\sigma} \subseteq \delta\vset_j$ of an odd-parity cluster $c_j$ have the same syndrome-vertex $v_\sigma$ located a minimum distance $d_i = |(v_i, v_\sigma)|$ on a path supported by edges in $\m{E}_j$. As a growth iterations means to grown all boundaries, all distances $d_i$ have the same value. A hypothetical matching $\m{C}$ with an other odd-parity cluster on vertex $v_i$ must contain edges $(v_i, v_\sigma)$, since $c_j$ is a tree. Furthermore, $\m{E}_j\cap (\m{C} \setminus (v_i, v_\sigma))$ is independent from which vertex $v_i$ as long as they have the same seed. Thus the potential matching weight
  \begin{equation}
    PMW(v_i) = \abs{(v_i, v_\sigma)} + \abs{\m{E_j}\cap (\m{C} \setminus (v_i, v_\sigma))} = \text{ constant } \forall v_i \in \{v_1, v_2,...\}_{v_\sigma}. 
  \end{equation}
\end{proof}

\begin{definition}\label{def:node}
  Let a node $\gls{nnode}$ represent a subset of vertices of a cluster for which each vertex is seeded in the same seed vertex $v_{seed}$, which is denoted as $n.\vset$ in object notation. 
\end{definition}

\begin{definition}\label{def:nodeset}
  Let a cluster $c_j$ also be represent by a \emph{node set} $\gls{snodeset}_j = \{n_1, n_2, ...\}$, stored as a tree by its root node at the cluster $c.n_r$. The subset of $n_i.\vset$ containing vertices in the boundary $\delta\vset_j$ is denoted $n_i.\delta\vset$, where $\delta\vset_j \supseteq n_i.\delta\vset \subseteq n_i.\vset$. Let the combined set of all nodes on a graph be denoted as $\nset$.
\end{definition}

Per Theorem \ref{the:nodepmw} and Definition \ref{def:nodeset}, all boundary vertices of a node have the same potential matching weight. The calculation of the potential matching weights within a cluster can thus be limited to its node-tree $\nset_j$. From our previous example, each vertex in cluster $c_e$ is a syndrome-vertex. For each of the vertices, their seed syndrome vertices are themselves. The node-tree is thus $\nset_e = \{n_1, n_2, n_3\}$ where $v_1 \in n_1.\vset$, $v_2 \in n_2.\vset$ and $v_3 \in n_3.\vset$. As this cluster grows in size, the number of vertices in $\vset_e$ increases in each round, while the number of nodes in $\nset_e$ remains the same at 3 nodes (Figure \ref{fig:nodesetpmw}). The node-tree is thus a \emph{reduced tree} of cluster $c_i$ where each node contains a subset of vertices in $\vset_j$ and each edge of the \emph{reduced tree} is equivalent to one or more edges in $\m{E}_j$. Futhermore, as every node needs to be seeded in some vertex, the number of nodes $|\nset|$ is limited by the number of vertices on the lattice. 
\begin{equation}\label{eq:sets}  
  \abs{\nset} \leq \abs{\vset} 
\end{equation}
\input{tikzfigs/nodesetpmw.tex}

\subsection{Node types}

There are various types of nodes that behave slightly differently. In this section, we introduce the \emph{syndrome-node} and the \emph{linking-node}, which are required for decoding on a toric code. For bounded surfaces such as the planar code, the \emph{boundary-node} is required additionally, which is covered in Section \ref{sec:ufbbbound}. 

\begin{definition}\label{def:syndromenode}
  Let a syndrome-node $\gls{nsyndromenode}$ denote a node that is seeded in a syndrome-vertex. 
\end{definition}

The node type that we have described in the previous section is a syndrome-node. Boundary vertices $v_i$ of a syndrome-node have a single seed syndrome-vertex for which there exists a minimum distance $d_i$ as stated in the proof of Theorem \ref{the:nodepmw}. This is true if all syndrome vertices are located an odd distance from each other. But this is not the case at all as the distance between syndrome vertices is only limited by the discrete nature of the lattice and the size and boundary (if it exists) of the lattice itself. For two syndrome vertices $v_1, v_2$ located an even distance from each other, each seeds a syndrome-node $s_1, s_2$, there exists some vertex $v_{l}$ that lie in equal distance to both syndromes. If the clusters of $s_1, s_2$ grow and reach vertex $v_{l}$ in the same growth iterations, it is not clear to which syndrome-node $v_l$ belongs, or which vertex $v_1$ or $v_2$ seeds $v_l$. 

\begin{definition}\label{def:linkingnode}
  Let a linking-node $\gls{nlinkingnode}$ denote a node that is seeded in a vertex that lies in equal distance to two or more seeds of other nodes. 
\end{definition}

This problem is solved by initiating a linking-node $l$ with the vertex $v_l$ as its seed. By doing so, every boundary vertex of the nodes $s_1$ and $s_2$ is limited to have a single nearest syndrome-vertex, which are $v_1$ and $v_2$, respectively. For the linking-node, every boundary vertex in $l.\delta \vset$ is limited to have a single nearest \emph{linking-vertex} $v_l$, which is its seed. We can replace every instance of $v_\sigma$ in Theorem \ref{the:nodepmw} and its proof with $v_l$ to see that the theorem also holds for linking-nodes. Thus a linking-node also has the property that its boundary vertex set $l.\delta \vset$ has the same potential matching weight. Note that a linking-node initiated on a vertex that lies in equal distance to the seeds of \emph{any} node, thus including other linking-nodes. 

Consider our example cluster $c_e$ of 3 nodes $\{n_1, n_2, n_3\}$ again. Now we slightly alter this cluster by increasing the distance between the seeds $v_1, v_2$ and $v_2, v_3$ to two edges. This means that cluster $c_e$ is only established after two growth iterations of the three previous separate cluster of node-trees $\{n_1\}, \{n_2\}, \{n_3\}$, and has a total size of 13 vertices (Figure \ref{fig:linkingode}). Now consider the vertices $v_{12}$ and $v_{23}$ that lie between $v_1, v_2$ and $v_2, v_3$, respectively. These are linking-vertices as they lie in equal distance to two seeds. Thus in the node-tree of the merged cluster $\nset_e$, linking-nodes $l_{12}$ and $l_{23}$ are initiated. 
\input{tikzfigs/linkingnode.tex}

% It is not clear in which nodes these vertices are seeded, as they lie in equal distance to two nodes. To solve this, a new type of node called \emph{linking-nodes} $j$ is initiated on the merging vertices, which lie on the linking of two flowers. All nodes $j$ have the same characteristics of syndrome-nodes $\sigma$; they have their own flowers and can thus be separately delayed during growth.
% \begin{lemma}\label{lem:linkingode}
%   On a merging vertex $v$ that lies in equal distance to two syndrome-nodes from two separate clusters merging into one, a linking-node $j$ is initiated in the joined node-tree $\nset$. A linking-node has the same properties as a syndrome-node.
% \end{lemma}

% The union of the set of linking-nodes $\m{J}$ and set of syndrome-nodes (syndromes) $\sigma$ is equal to the node-tree $\m{N}$. A vertex can either be a node in the syndrome-node-tree, a node in the linking-node-tree, or not a node at all, but never both $\sigma$ and $\m{J}$ as these sets are mutually exclusive. The node-tree size $S_\nset$, is therefore upper-bounded by the cluster size or vertex-tree size $S_\vset$, as all nodes are vertices, but not all vertices are nodes.
% \begin{eqnarray}
% % \nonumber % Remove numbering (before each equation)
%   \m{N} \subseteq \m{V} &,& S_\nset \leq S_\vset \label{eq:sets}  \\
%   \nonumber \sigma &\cup& \m{J} = \m{N} \\
%   \nonumber \sigma &\cap& \m{J} = \emptyset
% \end{eqnarray}

\subsection{Balanced-bloom}

The data structure of the node-tree can be utilized to to delay the growth of boundaries with a high potential matching weight, or prioritize the growth of boundaries with a low potential matching weight, as the boundaries confined in each node have the same potential matching weight per Theorem \ref{the:nodepmw}. In order to do so, the growth of a cluster must be separated for the nodes in its node-tree. 

\begin{definition}\label{def:bloom}
  Let the \emph{bloom} of a node $n_i$ refer to the growth of the boundaries $n_i.\delta\vset$. The growth for all boundaries of a cluster $
  \delta\vset_j$ is the equivalent to the combined bloom of all nodes in its node-tree $\nset_j$. Let the radius of a node $n_i.r$ be the number of iterations it has bloomed. 
\end{definition}

% The node-tree $\m{N} = \{n_1, n_2, .... n_{S_{\nset}}\}$ is stored as a tree, an connected and acyclic graph, where the edges $\epsilon$ between the nodes are the branches in our figurative flower bush. Each node-edge $\epsilon$ can have arbitrary length and consists of one or more vertex-edges $e$. For any node-tree $\nset_j$, we would prefer that the difference PMW for all nodes in the set to be minimal.
In the search of a minimal weight matching, the growth of a cluster can thus prioritize the bloom of nodes with the lowest potential matching weight, and delay the bloom of nodes with larger potential matching weight. As these prioritized nodes bloom and increase in radius, the cluster moves towards equal potential matching weight across all nodes, where in each iteration the number of delayed nodes decreases. Once the equilibrium is reached, no nodes are delayed.
\begin{definition}\label{def:balancedbloom}
  Balanced-bloom is the state of growth of a odd-parity cluster $c_j$ when all nodes in its node-tree $\nset_j$ have the same potential matching weight, and thus all nodes in $\nset_j$ are bloomed. This state can be reached by prioritizing the growth of nodes with the lowest potential matching weight. 
\end{definition}
\begin{lemma}\label{lem:calconce}
  Between union events, the potential matching weight of nodes in a clusters need only to be calculated once. The delayed node can be queued for some iterations based on the difference of its own potential matching wight and the minimal potential matching weight in the cluster.
\end{lemma}
\begin{proof}
  While no unions between clusters occur, the cluster will be defined by the same set of nodes. The potential matching weight of nodes in the cluster is then defined by the some potential matching $\m{C}$ (Theorem \ref{the:nodepmw}). The changes to the potential matching weight of a node $n_i$ due to the growth of the cluster, or some iterations of bloom, is directly related to its radius $n_i.r$. As we can store the radius as an attribute of the node, the altered potential matching weight is then simply a $\m{O}(1)$ calculation involving its old value and $n_i.r$. 
\end{proof}

To finalize, the node-tree $\nset_j$ of a cluster $c_j$ is a reduced tree of the graph formed by $\vset_j$ and $\m{E}_j$, and is thus also a connected acyclic graph. The node-tree is stored by its root node $n_r \in \nset_j$ at the cluster $c_j.n_r$. As node-trees merge and linking-nodes are initiated, children nodes added to the set by connecting them to the parent nodes by \emph{undirected} edges. This is different from $\vset$ which utilizes the Union-Find data structure (Section \ref{sec:ufdata}), which has \emph{directed} edges that point to the root. We will see in the next section why this is the case. 



% To be able to bloom each node separately, we cannot store the boundary edges of a cluster in a single list $\m{L}$ at the cluster. Instead, we store the boundary list for each node $n_i$ separately in their own boundary lists $n_i.\m{L}$. As we will see in the next section, the calculation of node-delays is dependent on the direction in which $\m{N}$ is traversed. We store the node-tree by its root $n_r$ at the cluster $C$.
% \begin{figure}
%   \centering
%   \begin{tikzpicture}
%     \draw[l1] (0,0) circle [x radius = 4cm, y radius = 2cm];
%     \draw[l1] (1,0) circle [x radius = 2.9cm, y radius = 1.4cm, line width=1];
%     \draw[l1, dashed] (1,0) circle [x radius = 3cm, y radius = 1.5cm];
%     \draw[l1] (1,1.4) -- (1,-1.4);
%     \node at (-3, 0) {$\m{V}$};
%     \node at (-.5, 0) {$\m{S}$};
%     \node at (2.5, 0) {$\m{J}$};
%     \node at (-2.5, -1) (nnode) {$\m{N}$};
%     \draw (-2, 0) -- (nnode) ;
%   \end{tikzpicture}
%   \caption{The space occupied by the sets of vertices $\vset$ and nodes $\nset$ (union of syndrome-node-tree $\mathcal{S}$ and linking-node-tree $\mathcal{J}$).}\label{fig:sets}
% \end{figure}

% \begin{theorem}
%   The set of nodes $\m{N} = \{n_1, n_2, .... n_{\nset}\}$ of cluster $C$ is a connected acyclic graph with root $n_r$, and exists next to the exists set of vertices $\m{V}$. The function of $\m{N}$ is to store the list of boundary edges at the nodes and to selectively bloom each node dependent on some calculated delay.
% \end{theorem}


\section{Node parity and delay}\label{sec:nodedelay}
The node-tree data structure allows for a reduction in the calculation of the potential matching weight, as the value for boundary vertices within the node are equal. However, if this calculation is done naively by calculating the potential matching weight for each node individually, where in each calculation the entire node-tree is traversed, the full calculation runs in quadratic time. Luckily, as we will explore in this section, the node-tree data structure allows us to calculate several values that relate closely to the potential matching weight; the \emph{node parity} and \emph{node delay}, by two depth-first searches from the root node. 

\begin{definition}\label{def:nodedelay}
  Let the \emph{node delay} $n.d$ be the the difference in the number of bloom delay iterations of a node $n$ and the root node $n_r$ in the node-tree of an odd-parity cluster.
\end{definition}

\begin{definition}\label{def:nodeparity}
  Let the \emph{node parity} $n.p$ be an indicator for whether the a node $n_\beta$ has a larger delay compared to its parent $n.\alpha$ in an odd-parity cluster; for even parity $n_\beta.p=0$ then $n_\beta.d < n_\alpha.d$, and for odd parity $n_\beta.p=1$ then $n_\beta.d > n_\alpha.d$. Even nodes are relatively prioritized and odd nodes are relatively delayed.
\end{definition}

\begin{theorem}\label{the:delayequation}
  The node parity of a node $n_\beta$ is only dependent on its own attributes and its children $\{n_{\gamma,1}, ...\}$:
  \begin{equation}\label{eq:nodeparity}
    n_\beta.p =
    \begin{cases}
      \big( \sum_{n_\gamma} (1-n_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} n_\gamma \text{ child node of } n_\beta & n_\beta \equiv s_\beta \\
      1 - \big( \sum_{n_\gamma} (1-n_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} n_\gamma \text{ child node of } n_\beta & n_\beta \equiv l_\beta.
    \end{cases} 
  \end{equation}
  The node delay of a node $n_\beta$ is only dependent on its own attributes and its parent $n_\alpha$:
  \begin{multline}\label{eq:delayequation}
    s_\beta.d = s_\alpha.d + \Bigg \lceil f_{eq} \Bigg( 2\bigg(\ceil{\frac{s_\beta.r}{2}} - \floor{\frac{s_\alpha.r + s_\beta.r \bmod 2}{2}} - (-1)^{s_\beta.p}\abs{(s_\beta,s_\alpha)}\bigg)
    \Bigg) - \\
    (s_\beta.r - s_\alpha.r) \bmod 2 \Bigg \rceil \hspace{1em} | \hspace{1em} s_\beta \neq s_r.
  \end{multline}
  where $n.r$ denotes the node radius (Definition \ref{def:bloom}) and $f_{eq}$ is an optimization parameter.
\end{theorem}
\begin{proof}
  Equation \ref{eq:nodeparity} is proven by Lemmas \ref{lem:nodeparitypart} and \ref{lem:nodeparity}. 
\end{proof}

We will prove Theorem \ref{the:delayequation} throughout the following sections. In Section \ref{sec:1dnodetree}, we introduce the concept of node delays and parities on syndrome-nodes through an example of a one-dimensional node-tree. In Section \ref{sec:realisticnodetree}, the same concept is applied to realistic node-trees, which is the dimension of the surface code that applies to realistic node-trees. These concepts are extended to linking-nodes in Section \ref{sec:linkparitydelay}. In Section \ref{sec:bbstate}, we introduce the concept of the \emph{equilibrium-state} of a node-tree that optimizes the minimal weight behavior through the $f_{eq}$ parameter. Finally, the pseudo-codes for the calculation of node delays are listed in Section \ref{sec:pdccalc}.

\subsection{One-dimensional node-tree parity and delay}\label{sec:1dnodetree}
\input{tikzfigs/onedimensialtree.tex}
We introduce the concepts of node parity and node delay from Definitions \ref{def:nodeparity} and \ref{def:nodedelay} through a one-dimensional node-tree $\nset_{1D}$ of exclusively syndrome-nodes. In this simplification, all nodes lie on a horizontal line from $s_1$ to $s_{|\nset_{1D}|}$ (Figure \ref{fig:1dnodetree}). Let us calculate the potential matching weights (PMW) for the nodes in this cluster. Recall from Definition \ref{def:bloom} that the radius of the node $s.r$ is equal to number of bloom iterations, one half-edge on the boundaries per iteration. This means that if a merge with some other cluster occurs on a boundary edge of $s$, the weight of the matchings edges within the node $s$ is equal to $\floor{s.r/2}+1$ or. For a merge on $s_1$, the matching weight $|\m{C}|$ is the the sum of $\floor{s.r/2}+1$, the length of edges $(s_2,s_3), (s_4,s_5)$, and some value $k$ corresponding to the weight of matching edges in the remainder of the cluster. This calculation can be continued for other nodes:
\begin{eqnarray*}
% \nonumber % Remove numbering (before each equation)
  PMW(s_1) &=& \floor{s_1.r/2}+1 + \abs{(s_2,s_3)} + \abs{(s_4,s_5)} + k \\
  PMW(s_2) &=& \floor{s_2.r/2}+1 + \abs{(s_1,s_2)} + \abs{(s_2,s_3)} + \abs{(s_4,s_5)} + k \\
  PMW(s_3) &=& \floor{s_3.r/2}+1 + \abs{(s_1,s_2)} + \abs{(s_4,s_5)} + k\\
  &\vdots&
\end{eqnarray*}
The difference in the potential matching weight of a node $s_i$ and its parent $s_{i-1}$ has a more constant definition that is only dependent on the radii of $s_i$,  $s_{i-1}$, and the length of the edge connecting the two:
\begin{eqnarray*}
% \nonumber % Remove numbering (before each equation)
  PMW(s_2) - PMW(s_1) &=& \floor{s_2.r/2} - \floor{s_1.r/2} + \abs{(s_1,s_2)} \\
  PMW(s_3) - PMW(s_2) &=& \floor{s_3.r/2} - \floor{s_2.r/2} - \abs{(s_2,s_3)} \\
  &\vdots&
\end{eqnarray*}

There is a trend in which contribution of the edge length the difference in the potential matching weight is dependent on the \emph{parity} of the node number $i$. The difference $ PMW(s_{2i}) - PMW(s_{2i-1})$ for some integer $i$ has the positive addition of $|(s_{2i}, s_{2i-1})|$, whereas the difference The difference $ PMW(s_{2i+1}) - PMW(s_{2i})$ has the subtraction of $|(s_{2i}, s_{2i-1})|$. Thus we can generalize the difference as
\begin{equation}\label{eq:pmwdiff}
  PMW(s_i) - PMW(s_{i-1}) = \floor{\frac{s_i.r}{2}} - \floor{\frac{s_{i-1}.r}{2}} + (-1)^{i}\abs{(s_i,s_{i-1})} \hspace{1em} | \hspace{1em} i\geq 2.
\end{equation}

\begin{lemma}
  The difference in delay between a node $s_i$ and its parent $s_{i-1}$ is related to the difference in potential matching weight by 
  \begin{equation}\label{eq:delaydiff}
    s_i.d - s_{i-1}.d =2\big(PMW(s_i) - PMW(s_{i-1})\big) + f_{deg}(s_i.r, s_{i-1}.r) \hspace{1em} | \hspace{1em} i\geq 2,
  \end{equation}
  where $f_{deg}$ is a repair function accounts for the degeneracy of the potential matching weight with
  \begin{equation}\label{eq:degenrepair}
    f_{deg}(r_i, r_{i-1}) = (r_i - r_{i-1}) \bmod 2 \cdot \left(\frac{r_i - r_{i-1}}{\abs{r_i - r_{i-1}}}\right) \cdot (-1)^{\left(\frac{r_i+r_{i-1}-1}{2}\right)\bmod 2} .
  \end{equation}
\end{lemma}
\begin{proof}
  As the boundary edges grow only a half-edge per bloom, the difference in the node delays between a node $s_i$ and its parent $s_{i-1}$ is thus twice the difference in their potential matching weights. But also due to this discrete multiplication factor of 2 between the delay and the potential matching weight, there is a degeneracy when calculating the potential matching weights from the node radii. For example, the radii $s_i.r = s_{i-1}.r = 2k$ for some integer $k$ yields the same potential matching weight as $s_i.r = 2k$, $s_{i-1}.r = 2k + 1$.

  The degeneracy between the node radius $r_i$ and the parent node radius $r_{i-1}$ exists only if the difference between the radii is odd. This is due to the division by 2 and the subsequent floor function. Thus the degeneracy repair function $f_{deg}$ acts only when $(r_i - r_{i-1}) \bmod 2$ is 1. 
  
  Disregarding the length of edges between two subsequent nodes, for nodes $s_i, s_{i-1}$ with radii $r_i-r_{i-1}=1$, node $s_i$ is thus larger and should have delay $+1$ compared with node $s_{i-1}$. For radii $r_i-r_{i-1}=-1$, node $s_i$ should have delay $-1$ compared with node $s_{i-1}$. This can be simplified with
  \begin{equation}\label{eq:nodediff}
    s_i.d - s_{i-1}.d = \frac{r_i - r_{i-1}}{\abs{r_i - r_{i-1}}} \hspace{1em} | \hspace{1em} \abs{r_i - r_{i-1}} = 1.
  \end{equation}
  
  Futhermore, we find that the degeneracy is caused by a non-linearity in the difference of the potential matching weights:
  \begin{equation}\label{eq:nonlinear}
    \floor{r_i/2}-\floor{r_{i-1}/2} = 
    \begin{cases}
      \pm 2\abs{r_i - r_{i-1}} & \text{if } \left(\frac{r_i+r_{i-1}-1}{2}\right)\bmod 2 = 1 \\
      \pm 2(\abs{r_i - r_{i-1}} - 1) & \text{else}.
    \end{cases}
  \end{equation}
   The non-linearity can be accounted for by combining Equation \eqref{eq:nodediff} with the condition of Equation \eqref{eq:nonlinear} to obtain the repair function of \eqref{eq:degenrepair}, which proves the lemma. 
\end{proof}

Combining Equations \eqref{eq:pmwdiff} and \eqref{eq:delaydiff}, we find that the delay of a node is defined as
\begin{multline}\label{eq:1ddelaycomp}
  s_i.d = s_{i-1}.d + 2\bigg(\floor{\frac{s_i.r}{2}} - \floor{\frac{s_{i-1}.r}{2}} + (-1)^{i}\abs{(s_i,s_{i-1})}\bigg) + \\
  (s_i.r - s_{i-1}.r) \bmod 2 \cdot \left(\frac{s_i.r - s_{i-1}.r}{\abs{s_i.r - s_{i-1}.r}}\right) \cdot (-1)^{\left(\frac{s_i.r+s_{i-1}.r-1}{2}\right)\bmod 2} \hspace{1em} | \hspace{1em} i\geq 2,
\end{multline}
which can be further simplified to 
\begin{multline}\label{eq:1ddelay}
  s_i.d = s_{i-1}.d + 2\Bigg(\ceil{\frac{s_i.r}{2}} - \floor{\frac{s_{i-1}.r + s_i.r \bmod 2}{2}} + (-1)^{i}\abs{(s_i,s_{i-1})}\Bigg) - \\
  (s_i.r - s_{i-1}.r) \bmod 2 \hspace{1em} | \hspace{1em} i\geq 2,
\end{multline}
where the repair function $f_{deg}$ has been partially moved into the main part of the function. We will not provide a description of this simplification, but Equation \eqref{eq:1ddelay} has the exact same output as Equation \eqref{eq:1ddelaycomp}. 

Using equation \eqref{eq:1ddelay}, we can calculate all the node delays in the one-dimensional node-tree by setting some initial delay for $s_1$, for example $s_1.d=0$. This is why the node delay is defined as the difference in the bloom delay iterations between a node and the root node, which is $n_r=s_1$ in the one-dimensional node-tree. The node delay can thus also take negative values, as the choice for $s_1.d$ is arbitrary. The absolute delay, the number of iterations for a node to wait, can then be calculated by subtracting the minimum delay in the node-tree $\min \{s.d | s \in \nset_{1D}\}$. Not to mention, as the potential matching weight does not change between union events (Lemma \ref{lem:calconce}), the node delays do not have to be recalculated in every iteration. This means that it is necessary to additionally to the number of iterations a node has waited.
\begin{definition}\label{def:absolutedelay}
  Let $n.w$ denote the number of bloom iterations a node $n$ has already \emph{waited}, then the \emph{absolute delay} $n_i.D$ of a node $n_i$ in a cluster $c_j$ with node-tree $\nset_j$ is the actual number of blooms to wait at any given moment. The absolute delay is calculated with
  \begin{equation}\label{eq:absulutedelay}
    n_i.D = n_i.d - c_j.d - n.w, 
  \end{equation}
  where $c_j.d$ is the minimal delay value in the cluster
  \begin{equation}\label{eq:cd}
    c_j.d = \min \{n.d \hspace{.5em} | \hspace{.5em} n\in \nset_j\}.
  \end{equation}
\end{definition}
% The difference between the root delays and the minimal root delay value in the cluster relates to the PMW.
% \begin{equation}\label{eq:pmw}
%   PMW(n_i) = n_i.d - \min \{s_1.d,...,n_{S_\nset-1}.d\} + K - n.w
% \end{equation}
% Here, the constant $K$ is equal to the lowest PMW in the cluster. Recall from theorem \ref{def:balancedbloom} that the algorithm searches for the lowest PMW nodes in the cluster, thus the value of $K$ is irrelevant for our algorithm. The variable $n.w$ stores the number of iterations a node has waited based on its calculated delay value, which is equivalent to the queue in lemma \ref{lem:calconce}, and will be clarified in \ref{sec:growingcluster}. If we store the minimal delay value in the cluster at the cluster object with
% \begin{equation}\label{eq:cd}
%   C.d = \min \{s_1.d,...,n_{S_\nset-1}.d\},
% \end{equation}
% we can define a \emph{Potential Normalized Weight} (PNW) that is normalized in $K$,
% \begin{equation}\label{eq:pnw}
%   PNW(n_i) = n_i.d - C.d - n.w.
% \end{equation}
% Balanced-Bloom in a cluster is now achieved by blooming the nodes that has $PNW(n_i) = 0$. Additionally, we can define a normalized delay (ND) of a node that is equal to the actual number of iterations for a node to wait:
% \begin{equation}\label{eq:ad}
%   ND(n_i) = n_i.d - C.d.
% \end{equation}
Note that in Definition \ref{def:absolutedelay}, the general node element $n$ is used in stead of the syndrome-node $s$. This definition also holds for other types of nodes, such as linking-nodes (Section \ref{sec:linkparitydelay}) or boundary-nodes (Section \ref{sec:ufbbbound}). The balanced-bloom state (Definition \ref{def:balancedbloom}) is thus reached when $n_i.D = 0$ for all nodes in the node-tree. 

\subsection{Realistic node-tree parity and delay}\label{sec:realisticnodetree}

The one-dimensional node-tree from the previous section does not accurately represent node-trees that occupy a real lattice. On a two-dimensional lattice (independent noise) and a three-dimensional lattice (phenomenological noise), the node-tree $\nset$ is allowed to form in the same dimensions as an acyclic graph, in stead of a linear set with index number $i$. The delay calculation on an entire node tree is not a sequence of calculations from node $s_1$ to $s_{|\nset_{1D}|}$, but a depth-first search from the root node $s_r$. Just as the previous section, we assume that $\nset$ has excursively syndrome-nodes. Using the same strategy as in the previous section, we find that the equation for calculating the node delays is quite similar. The delay calculation is performed on a node $s_\beta$ comparatively with the parent node $s_\alpha$, which means that there must be some directed path within $\nset$, such that there is a clear direction, and the calculation is started from the root node $s.r$ by setting $s.r.d=0$.

The edge contribution to the node parity $|(s_\beta, s_\alpha)|$, whose sign was previously determined by the node index $i$, is now set by the node parity (Definition \ref{def:nodeparity}). 
\begin{lemma}\label{lem:nodeparitypart}
  For a node-tree of exclusively syndrome-nodes, the concept of the node parity can be defined as the number of descendant nodes modulo 2 (see Figure \ref{fig:parities}). It can be calculated without counting the number of descendants for every node by using the recursive relation where the parity of a node $n_\beta$ is only dependent on the parities of its immediate children $n_\gamma$:
  \begin{equation}\label{eq:nodeparitypart}
    s_\beta.p = \big( \sum_{s_\gamma} (1-s_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} s_\gamma \text{ child node of } s_\beta.
  \end{equation}
\end{lemma}
\begin{proof}
  For a node $s_\beta$ with a set of children nodes $\{s_\gamma, ...\}$, the node parity $s_\beta.p$ can only be even if it has an even number of children nodes with even parity $s_\gamma.p = 0$, and a even number of children nodes with odd parity $s_\gamma.p=1$. This is accomplished by Equation \ref{eq:nodeparitypart}. 
\end{proof}
Note that this definition of the node parity is identical as in a one-dimensional syndrome-node-tree, where a node with an odd index effectively has an even number of descendent nodes and results in a contribution $-|(s_i, s_{i-1})|$, and an even indexed node results in a contribution $+|(s_i, s_{i-1})|$. The parity calculation thus requires the parity of every child node to be known, which means that the parity calculation of $\nset$ is related to a depth-first search from the root node $s_r$, with a tail-recursive function to calculate the parities from the bottom up. To calculate the node delays within $\nset$, a second depth-first search is applied with
% \begin{multline}
%   n_\beta.d = n_\alpha.d + 2\bigg(\floor{\frac{(n_\beta.s+n_\beta.g)}{2}} - \floor{\frac{(n_\alpha.s+n_\beta.g)}{2}} + (-1)^{n_\beta.p-1+1}(n_\alpha,n_\beta)\bigg) \\
%          - (n_\beta.g + n_\alpha.g)\bmod 2 \hspace{.5cm} | \hspace{.5cm} n_r.d = 0, \hspace{.2cm} n_\beta \mbox{ child of } n_\alpha,
% \end{multline}
\begin{multline}\label{eq:2ddelay}
  s_\beta.d = s_\alpha.d + 2\Bigg(\ceil{\frac{s_\beta.r}{2}} - \floor{\frac{s_\alpha.r + s_\beta.r \bmod 2}{2}} - (-1)^{s_\beta.p}\abs{(s_\beta,s_\alpha)}\Bigg) - \\
  (s_\beta.r - s_\alpha.r) \bmod 2 \hspace{1em} | \hspace{1em} s_\beta \neq s_r.
\end{multline}
where $n_\beta$ is the node of interest and $n_\alpha$ is an parent of $n_\beta$, and the sign of the edge component is now dependent on the node parity $s.p$.

\input{tikzfigs/parities.tex}

\subsection{linking-node parity and delay}\label{sec:linkparitydelay}

Up until now, the existence of linking-nodes has been neglected in the node parity and delays calculations. In this section, we will extend upon the previous equations for node parity and delay to include linking-nodes. Luckily, the delay calculation of Equation \eqref{eq:2ddelay} still holds for linking-nodes. However, the parity of a linking-node is calculated differently. Consider an example node-tree $\nset_s$ with 5 syndrome-nodes $\{s_1,...,s_5\}$ lined up linearly with distance 1 between them and $n_r = s_1$ (Figure \ref{fig:linkingparity}a). Let us consider a delay $n.d^*$ from Equation \eqref{eq:2ddelay} but leaving out the node radius components as we are now only interested in the parity component $- (-1)^{s_\beta.p}\abs{(s_\beta,s_\alpha)}$. The parity of $s_4$ is odd, therefore
\begin{equation*}
  s_4.d^* = s_3.d^* + 2(s_3, s_4).
\end{equation*}

\input{tikzfigs/linkingparity.tex}

Consider now a second example node-tree $\nset_l$ with 3 syndrome-nodes and 2 linking-nodes $\{s_1, l_2, s_3, l_4, s_5\}$ (Figure \ref{fig:linkingparity}b). Recall that a linking-node does not have a syndrome-vertex as seed, and thus matchings must occur between seeds of the syndrome-nodes. The potential matching weights without the radius component $PMW^*$ in $\nset_l$ are
\begin{align*}
  PMW^*(s_1) &= \abs{(s_1, l_2)} + \abs{(l_1, s_3)} + \abs{(l_3, l_4)} + \abs{(l_4, s_5)} \\
  PMW^*(l_2) &= \abs{(s_1, l_2)} + \abs{(l_3, l_4)} + \abs{(l_4, s_5)} \\
  PMW^*(s_3) &= \abs{(s_1, l_2)} + \abs{(l_1, s_3)} + \abs{(l_3, l_4)} + \abs{(l_4, s_5)} \\
  PMW^*(l_4) &= \abs{(s_1, l_2)} + \abs{(l_1, s_3)} + \abs{(l_4, s_5)} \\
  PMW^*(s_5) &= \abs{(s_1, l_2)} + \abs{(l_1, s_3)} + \abs{(l_3, l_4)} + \abs{(l_4, s_5)},
\end{align*}
and the delays in $\nset_l$ are 
\begin{align*}
  l_2.d^* &= s_1.d^* + 2(l_2, s_1)\\
  s_3.d^* &= l_2.d^* + 2(s_3, l_2)\\
  l_4.d^* &= s_3.d^* - 2(l_4, s_3)\\
  s_5.d^* &= l_4.d^* - 2(s_5, l_4).
\end{align*}

\begin{lemma}\label{lem:nodeparity}
  The parity equation \eqref{eq:nodeparitypart} can be altered to apply for both syndrome-nodes as well as linking-nodes by   
  \begin{equation}
    n_\beta.p =
    \begin{cases}
      \big( \sum_{n_\gamma} (1-n_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} n_\gamma \text{ child node of } n_\beta & n_\beta \equiv s_\beta \\
      1 - \big( \sum_{n_\gamma} (1-n_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} n_\gamma \text{ child node of } n_\beta & n_\beta \equiv l_\beta.
    \end{cases}\tag{\ref{eq:nodeparity}}
  \end{equation}
\end{lemma}
\begin{proof}
  The node parities of subsequent syndrome-nodes in a node tree should be independent on the number of intermediate linking-nodes, as the matchings only occur between the syndrome-vertex seeds of the syndrome-nodes. The parities of the intermediate linking-nodes should thus satisfy this requirement. By applying 1 minus the definition for the parity of a syndrome-node, the parity of the nearest descendant syndrome-node is effectively passed on to the linking-node, such that the parity flip only occurs at the next syndrome-node when moving upwards in the node-tree. 
\end{proof}

% To put this into perspective of lemma \ref{lem:anynoderoot}, the parity of a syndrome-node is the number of children \emph{syndrome}-nodes. The parity of a linking-node is 1 minus the number of children syndrome-nodes. From here, our definitions of parity and delay calculation stay unchanged; the parities can to be calculated by a reversed DFS of the node-tree from the root with equation \eqref{eq:nodeparity}, and the delays by a second DFS with equation \eqref{eq:2ddelay}.

\subsection{Node tree ancestry}


Recall from the last paragraph of Section \ref{sec:nodeset} that the edges of the node tree are \emph{undirected}. However, the depth-first searches to calculate the node parities and delays clearly indicates that there is some ancestry in the node tree. In this section, we will clarify this feature of the node-tree. 
\begin{lemma}\label{lem:anynoderoot}
  Any node $n_i \in \m{N}$ is a valid root. The root $n_r$, which has parity $n_r.p=0$, determines the node parities within the node-tree. 
\end{lemma}
\begin{proof}
  Since the node parities are calculated from the descendants to the root, and the node delays are subjected to an arbitrarily chosen delay for the root $n_r.d$, any node in $\nset$ can be chosen as the root. Recall from Definition \ref{def:nodeparity} that the node parity is only defined for an odd-parity cluster. For a node-tree of exclusively syndrome-nodes, this means that $n_r$ must have an even number of descendant nodes, and thus per Lemma \ref{lem:nodeparitypart} it must be that $s_r.p=0$. From a node-tree of mixed syndrome-nodes and linking-nodes, recall from Lemma \ref{lem:nodeparity} that linking-nodes always copies the parity of the nearest descendant syndrome-node, thus $n_r.p=0$. Choosing which node $n_i \in \nset$ is the root node $n_r$ for this reason determines the parities in the node-tree (see Figure \ref{fig:parities}). 
\end{proof}

The node-tree has undirected edges, such that it is not set in stone which node is the root. When to clusters merge into one, their respective node trees need to be merged too. As the edges in the node-tree reflect one or many physical edges on the lattice, the merge of node-trees can not be applied by simply pointing one root to another, such as in the Union-Find data structure. In stead, the node-trees $\nset_i, \nset_j$ are joined on the nodes $n_i \in \nset_i, n_j\in \nset_j$ containing the boundary vertices that support the newly grown edge that links the clusters. This can be done by setting one of the nodes $n_i$ or $n_j$ as the \emph{subroot} if its tree and connecting it with the other. This motivates the use of undirected edges. New roots can be chosen that allows for the union of node-trees. More on the union of node-trees is described in Section \ref{sec:nodejoin}. 

\begin{lemma}\label{lem:nodecalc_ancestrypath}
  The calculated node delays $n_i.d$ are only valid while node parities have been calculated with the same root node $n_r$. The absolute delay $n_i.D$ is independent on the selected root node. 
\end{lemma}
\begin{proof}
  Since both the calculation of the node parities and node delays are performed by a depth-first search of the node tree, and the node parities are dependent on which node is set as root (Lemma \ref{lem:anynoderoot}), it is trivial that the node delay calculation should follow the same depth-first search as the parity calculation. The absolute delay $n_i.D$ is independent on root node as it is the node delay $n_i.d$ minus the minimal delay in the cluster $c.d$ (Definition \ref{def:absolutedelay}). Recall that the node delay value the difference with $n_r.d$, whose value is arbitrary. By subtracting the minimal delay value in the cluster, this arbitrariness is accounted for. 
\end{proof}


%  An interesting aspect of the node delays is that the differential delays $\delta(n.d)$ are indifferent for which node is set as root $n_r = n$. The root delay value $n.d$ however may differ for different roots as de delay value for the root node is arbitrary. But as we subtract by the minimal delay $C.d$ to find the normalized delay, the root dependance of node PMW and node PNW is accounted for. This fact strengthens lemma \ref{lem:anynoderoot}.

\subsection{Equilibrium optimization}\label{sec:bbstate}

In this section, we alter the delay equation \eqref{eq:2ddelay} with an extra parameter $f_{eq}$ to optimize a trade-off in this algorithm. This trade-off occurs in about $50\%$ of the node-tree unions in an event that we dub \emph{parity-inversion}. Recall from Lemma \ref{lem:calconce} that after an union, the potential matching weight within the node-tree changes, and the parities and delays may have to be recalculated. Note that we will describe in Section \ref{sec:growingcluster} necessary steps to actually grow a cluster with the node-tree data structure, and in Section \ref{sec:nodejoin} we describe how to actually merge node-trees. In this section, the focus is on what happens to the potential matching weight and the subsequent required recalculation of the node parities and delays. 

% Consider the case of an union between an even-parity node-tree $\nset^e$ on the node $n_e\in\nset^e$ and an odd-parity node-tree $\nset^o$ on node $n_o\in \nset^o$. The merged tree is an odd-parity with tree $\nset^o_m$ with the subtrees $'\nset^e$ and $'\nset^o$. The trees are merged by making $n_o$ the new subroot of $'\nset^O$ and connecting $n_o$ with $n_e$. As an 
% If some odd number of nodes $\nset^o$ is attached to $n_e$ of $\nset^e$ during an union of the two node-trees, node parities for nodes in subset $'\nset^e= \{n_i \in \nset^e | n_i \mbox{ ancestor of } n^e\}$ are flipped, where odd nodes become even and even become odd, which is called \emph{parity inversion}. Per lemma \ref{lem:anynoderoot} and \ref{lem:nodecalc_ancestrypath}, the delays in $'\nset^e$ are now undefined and need to be recalculated. Before the union, the cluster of $'\nset^e$ is grown according to Balanced-Bloom, where the odd nodes are delayed and consequently the even nodes will have some node sizes larger than the odd node sizes $n^e_{even}.s > n^e_{odd}.s$.
% After the union, the parities for nodes in $'\nset^e$ flip, and the pre-union even nodes are now odd and have some positive delay. As $n^e_{even}.s > n^e_{odd}.s$, the absolute delays (equation \eqref{eq:ad}) of these nodes are larger than the absolute delays of the pre-union odd nodes per equation \eqref{eq:2ddelay}. Subsequent parity inversions further increases the absolute delays in the post-union odd nodes.
When clusters grow in size, their nodes are delayed such that the equilibrium in the potential matching weight can be reached. Because of this, the prioritized nodes have larger radii than the delayed nodes. As clusters merge, their node-trees are also joined on the nodes that contain the vertices supporting the connecting edge. Due to the merges, the parities of nodes in parts of the joined node-tree may flip, which we dub parity inversions. This means that the previously prioritized nodes become the nodes to be delayed, and the previously delayed nodes are to be prioritized. As these nodes have already grown in different radii, the parity inversion causes that after the flip in priority, it takes twice as many iterations to reach the equilibrium in potential matching weight. As more and more unions occur, the number of parity inversions increases and so does the number of iterations needed to reach equilibrium. 

\begin{definition}\label{def:eqstate}
  The equilibrium-state $(I:M)$ of cluster describes the degree of potential matching weight equilibrium in the cluster with node-tree $\nset$, where $M$ is the number of iterations with delayed blooms needed to reach equal potential matching weight, and $I\leq M$ is the number of iterations grown while equal potential matching weight has not been reached (Figure \ref{fig:eqstate}). The $(M:M)$ equilibrium-state is maximally occupied when all nodes in the node-tree have equal potential matching weights, and is thus equivalent to the balanced-bloom state of Definition \ref{def:balancedbloom}. 
\end{definition}
\begin{figure}
  \centering
    \begin{tikzpicture}
      \DSPECTRUM{4}{2}{1}
      \draw (-1.5,.5) node[align=right] {Unbalanced} ++(6.6,0) node[align=left] {Balanced};
    \end{tikzpicture}
  \caption{Visual representation of the equilibrium-state $(2:4)$. The size of the full x-axis is $M=4$ and the length of the bar is $I=2$. The left side of the spectrum is equivalent to the unbalanced equilibrium-state, and the right the balanced state.}\label{fig:eqstate}
\end{figure}
For example, a cluster with $M=4$ requires 4 growth iterations to reach an equilibrium in potential matching weight in all nodes in the cluster. The equilibrium-state thus gives us an indication of the how near balanced-bloom a cluster performs. 
\begin{lemma}
  Let $(I_t, M_t)$ denote the equilibrium-state of a cluster just before an union with another cluster that causes a parity inversion, and $(I_{t+1}, M_{t+1})$ the equilibrium-state after union, then $I_t \propto M_{t+1}$.
\end{lemma}
\begin{proof}
  In the context of the equilibrium-state, the delayed bloom of nodes in cluster growth is equivalent to increasing the value of $I$ in the equilibrium-state. As $I_t\to M_t$, the difference between the radii of the prioritized and delayed nodes increases, thus also increases the iterations $M_a$ needed after the union and parity inversion. 
\end{proof}
Subsequent parity inversions cause a gradual but certain increase in $M$ of the equilibrium-state, depending on $(I_t:M_t)$ during the parity inversion at the union, requiring a growing number of growth iterations $I_{t+1}$ to reach the equilibrium-state $(M:M)_{t+1}$. As the lattice size is increased, the total number of unions of a cluster with other clusters also increases, leading to a growing number of parity inversions. Thus increasing the lattice size has the consequence that more growth iterations $I$ are needed to reach equilibrium-state $(M:M)$. This is the trade-off in the effectiveness of this algorithm. On the one hand, it is preferred that $I\to M$ to maximally occupy the equilibrium-state that is a heuristic for minimum-weight, but on the other, $I$ is also proportional to the number of iterations needed to actually reach $(M:M)$ due to parity inversions. 

\begin{definition}
  Let the \emph{equilibrium factor} $f_{eq}\in [0,1]$ be a target factor to the node delay. 
\end{definition}
\begin{lemma}
  The delay equation where the delays have a factor $f_{eq}\in [0,1]$ minimizes the trade-off caused by parity inversion. 
  \begin{multline}
    s_\beta.d = s_\alpha.d + \Bigg \lceil f_{eq} \Bigg( 2\bigg(\ceil{\frac{s_\beta.r}{2}} - \floor{\frac{s_\alpha.r + s_\beta.r \bmod 2}{2}} - (-1)^{s_\beta.p}\abs{(s_\beta,s_\alpha)}\bigg)
    \Bigg) - \\
    (s_\beta.r - s_\alpha.r) \bmod 2 \Bigg \rceil \hspace{1em} | \hspace{1em} s_\beta \neq s_r. \tag{\ref{eq:delayequation}}
  \end{multline}
\end{lemma}
\begin{proof}
  For any $f_{eq} < 1$, a cluster will never actually reach the $(M:M)$ equilibrium-state, but only $(f_{eq}M:M)$. Let the equilibrium-state with the equilibrium-state be thus be defined as $(I:f_{eq}M)$. Consequently, after a parity inversion, the difference in node radii between prioritized and delayed nodes is decreased, such $I\to f_{eq}M$ can be reached in a lower amount of growth iterations. 
\end{proof}

In Figure \ref{fig:kbloom} and \ref{fig:kbloom2} a comparison is made between the growth of a set of node-trees using Equation \eqref{eq:delayequation} with $f_{eq}=1$ (same as Equation \eqref{eq:2ddelay}) and with $f_{eq}=1/2$. We see that the number of iterations needed to maximally occupy the equilibrium state using $f_{eq}$ is halved both before and after the union with parity inversion when using $f_{eq} = 1/2$. 

The optimal value of $f_{eq}$ is dependent on the number of parity inversions, and consequently the lattice size, growth iteration, and the node-tree and cluster sizes $|\nset|, |\vset|$, with the goal of maximally occupying the equilibrium-state after the last parity inversion. We suspect that due to the fact that $M$ doubles after parity inversion, a constant factor of $f_{eq}=1/2$ should behave well on average. However, other values of $f_{eq}$ should be explored and optimizations dependent on these variables could be possible. 

\input{tikzfigs/equilibrium_state.tex}
 
\subsection{Parity and delay calculations}\label{sec:pdccalc}

With equation \eqref{eq:nodeparity} and \eqref{eq:delayequation}, we now finally have the tools to formulate the algorithms to calculate the node parities and delays. For a node-tree with root $n_r$, we can calculate the parities by calling the \emph{head recursive} function \codefunc{Calcparity} on $n_r$ in algorithm \ref{algo:calcparity}, where we do a reverse DFS of the node-tree. The node delays are calculated by calling the \emph{tail recursive} function \codefunc{Calcdelay} in algorithm \ref{algo:calcdelay}, where we perform a second DFS of the node-tree. These Parity and Delay Calculation will from this point be referred to as the PDC. A schematic of the directions of these calculations in an example node-tree is included in Figure \ref{fig:2dfs}.

\input{pseudocodes/calcparity.tex}
\input{pseudocodes/calcdelay.tex}
\input{tikzfigs/paritydelay.tex}

\section{Growing a cluster}\label{sec:growingcluster}
With the knowledge of previous section, we now have the equations and algorithms available to describe the steps to grow a cluster in the context of Union-Find Balanced-Bloom. Previously, in the Union-Find decoder, a cluster is grown with $\codefunc{Grow}(c_j, \m{L}_m)$ (Algorithm \ref{algo:ufgrow}). Here, the boundary edges connected to the vertices in $c_j.\delta\vset$ are grown by increasing the value of $e.support$. If $e.support = 2$, $e$ is added to the merging list $\m{L}_m$ to merge the vertex-trees at some later moment. 

In the node-tree data structure, the growth of a cluster is equivalent to a depth-first search of the node-tree, which will now be performed by $\codefunc{Ngrow}$ (Algorithm \ref{algo:bbgrow}). The boundary list for each cluster is not stored at the cluster $c_j$, but separately stored at each of the nodes $n_i$ in $\m{N}_j$ by $n_i.\delta\vset$. We travel to all $n_i \in \m{N}_j$ from the root $n_r$ and apply $\codefunc{Bloom}(n_i)$ (Algorithm \ref{algo:bloom}), which grows the boundaries for each node individually. Again, if an edge on the boundary are grown to $e.support = 2$, $e$ is added to the merging list $\m{L}_m$ to merge the vertex-trees and node-trees at some later moment. The merging of node-trees is considered in Section \ref{sec:nodejoin}. 

Recall from Theorem \ref{def:balancedbloom} that with Balanced-Bloom, the bloom of node with the lowest potential matching weight in the cluster are prioritized, whereas the bloom of of other nodes are delayed. Also, from Lemma \ref{lem:calconce}, in the absence of unions the delays are not recalculated after every growth iteration, but stored in memory at the nodes. Definition \ref{def:absolutedelay} introduced the absolute delay $n_i.D$, where the actual number of iterations to delay is updated via the minimal delay value $c_j.d$ in the cluster and the number of iterations already waited $n.w$. Thus when performing the depth-first search in \codefunc{Ngrow}, a node should be conditionally bloomed if only $n_i.D = 0$ is satisfied. If not, node $n_i$ is skipped, the wait $n.w$ is increased and search continues recursively on its children nodes. 

\input{pseudocodes/bloom.tex}
\input{pseudocodes/ngrow.tex}

\section{Joining node-trees}\label{sec:nodejoin}
Within the vertex-tree $\m{V}$, which utilizes the Union-Find data structure, \emph{path compression} and \emph{union by weight} or \emph{union by rank} are applied to minimize the depth of the tree and therefore minimizing the calls to the \codefunc{Find} function. Similarly, in the node-tree $\m{N}$, we would also like to apply a set of rules to minimize the calls to \codefunc{Calcparity} and \codefunc{Calcdelay}, which we will dub the parity and delay calculation minimization.

\begin{definition}\label{def:partialpdc}
  A partial parity or partial delay calculation, which will be often abbreviated to a partial calculation, is one associated with a depth-first search that is not initiated from the root node $n_r$, but some descendent node of $n_r$ in the node-tree. 
\end{definition}

This minimization is achieved by preserving the node parities and delays in subsets of the merged node-tree after union, and applying a partial calculation of the parities and delays in the remaining subsets if required. The recursiveness of both \codefunc{Calcparity} and \codefunc{Calcdelay} (Algorithms \ref{algo:calcparity} and \ref{algo:calcdelay}) ensures that this is possible. The tail-recursive parity calculation stops at the node where the depth-first search is started, and the head-recursive delay calculation now has a non-arbitrarily node delay. 

With the addition of the node-tree data structure, during merge of clusters $c_\alpha$ and $c_\beta$, we have to additionally merge the node-trees $\m{N}_{\alpha}$ and $\m{N}_\beta$ that requires its own set of rules that we will explain in this section. Let us first make a clear distinction between the various methods. For the merge of vertex-trees $\vset_\alpha, \vset_\beta$ we apply $\codefunc{Union}(v_\alpha, v_\beta)$ (Algorithms \ref{algo:unionweight} or \ref{algo:unionrank}), with the two vertices spanning the edge connecting two clusters as arguments. For the merge of node-trees $\nset_\alpha, \nset_\beta$, we introduce here $\codefunc{Join}(n^\alpha, n^\beta)$ (Algorithm \ref{algo:join}), which is called on the two nodes $n_\alpha, n_\beta$ that seed vertices $v^\alpha, v^\beta$, respectively. During a merge of two clusters, these routines are both applied on their respective sets. Within the context of the Union-Find Balanced-Bloom decoder, when either one of the expressions "merge clusters $C_\alpha$ and $C_\beta$", "the union of vertex-trees $\m{V}_\alpha$ and $\m{V}_\beta$" or the "join of node-trees $\m{N}_{\alpha}$ and $\m{N}_\beta$" is mentioned, it is always implied that both routines are executed

\begin{definition}\label{def:nodesetparity}
  Let the parity of a node-tree be the number of syndrome-nodes in the node-tree modulo 2. The parity of the node-tree is thus equivalent to the parity of its cluster. 
\end{definition}
\begin{definition}\label{def:oddevenjoin}
  Let us categorize the joins of two node-trees into two types: even-joins and odd-joins, depending on the parity of the node-tree after the join. An even-join may be the result of the join of two even node-trees or two odd node-trees, whereas an odd-join is the result of a the join of one odd node-tree and one even node-tree.
\end{definition}

% Only odd clusters with odd parity node-trees are grown in the UF-decoder. It may thus be tempting to conclude that a join must include at least one odd node-tree. This is however not true as within the same growth iteration, there may be many joins, where some odd cluster $\nset_1^o$ first joins with odd cluster $\nset_2^o$, but also joins with even cluster $\nset_3^e$. The second join is effectively between even clusters. Hence there are 3 types of joins: 1) odd-odd, 2) even-odd and 3) even-even, where even-odd is equivalent to odd-even. These joins can be put into 2 \emph{classes}, dependent on the parity of the resulting cluster. Both odd-odd and even-even joins to an even cluster and thus belongs to the even class join (E-join), whereas even-odd (and odd-even) joins to an odd cluster in the odd class join (O-join).

\begin{lemma}\label{lem:nodecalc_even}
  If node-trees merge into an even node-tree $\nset^e$, all node parities and delays within $\nset^e$ become invalid or \emph{undefined}. 
\end{lemma}
\begin{proof}
  Recall from Definitions \ref{def:nodeparity} and \ref{def:nodedelay} that the node parity and delay are only defined for odd-parity clusters. An even-parity cluster does not have a potential matching weight, as the matchings within the cluster are already defined. However, $\nset^e$ merge with another odd-parity cluster with node-tree $\nset^o$ in a larger odd-join. In that case, we might think about "reusing" some of the node parities and delays that were already calculated in $\nset^e$. To reuse prior calculated parities and delays, a depth-first search on $\nset^e$ is needed to find which sections are still valid, and which sections are not. This is especially the case when the clusters in the E-join are the results of joins within the same growth iteration. Checking the validity to reuse prior parities and delays then acquires the same complexity as redoing the calculation of parity and delays over the subtree $\nset^e$. Hence the node parities and delays in the joined set after an E-join are \emph{undefined}.
\end{proof}

\begin{lemma}\label{lem:nodecalc_odd}
  Consider an odd-join on nodes $n_j^e \in \nset^e, n_j^o\in \nset^o$, belonging to an even and an odd node-tree, respectively. Parity and delay calculations are minimized during if the node-trees are always joined by setting $n_j^e$ as the child of $n_j^o$. 
\end{lemma}
\begin{proof}
  If $n_j^e$ is made a child of $n_j^o$, $n_j^e$ is the new subroot of subtree $\nset^e$, and an even number of syndrome-nodes are now descendants of $n_j^o$, and parities within $\nset^o$ and its root are unchanged. Recall from Lemma \ref{lem:nodecalc_ancestrypath} that thus the delays in $\nset^o$ are also unchanged. A partial parity and delay calculation can now be initiated from $n_j^e$ and is proportional to $|\nset^e|$ (Figure \ref{fig:joinrules}b). If $n_j^o$ is made a child of $n_j^e$, an odd number of syndrome-nodes are descendants of $n_j^e$ and changes the parities in the ancestors of $n_j^o$ up to the root of the joined tree. The parities and delays now need to be recalculated in the entire tree, which is proportional to $|\nset^e| + |\nset^o|$ (Figure \ref{fig:joinrules}c). 
\end{proof}

\input{tikzfigs/oddevenjoin.tex}
% \subsection{O-joins}\label{sec:ojoin}

% Consider now an O-join between an even node-tree $\m{N}^e$ and an odd node-tree $\m{N}^o$ in nodes $n^e, n^o$ respectively, and assume that this join is due to the growth of odd cluster $\m{N}^o$ onto an "idle" $\m{N}^e$. The join of these two sets produces a new odd node-tree $\m{N}_{new}^o$ with subsets $'\nset^e$ and $'\nset^o$, referring to the original node-trees. We are provided with two choices, A) make $n^e$ child of $n^o$, or B) make $n^o$ child of $n^e$. The ancestry in the parent node-tree stays unchanged, but the ancestry in the child subset is changed by setting the joining node in the child set $n^c$ as the subroot of the child subset $'\m{N}^c$. This is allowed per lemma \ref{lem:anynoderoot}, but removes any calculated parities or delays per lemma \ref{lem:anynoderoot} and \ref{lem:nodecalc_ancestrypath}.

% For option A, an even number of nodes of $'\m{N}^e$ is attached to $n^o$, and the ancestry in $'\m{N}^o$ hasn't changed. The parities and delays in $'\m{N}^o$ stay valid and can be reused. From $n^e$, which is now the subroot of  $'\m{N}^e$, a partial PDC is applied, where the relative delay of $n^e$ is calculated with respect to its parent $n^o$ (Figure \ref{fig:joinrules}A). This is efficient as the parities and delays in $'\m{N}^e$ are already undefined per lemma \ref{lem:nodecalc_even}. For option B, we need to redo the PDC in both $'\m{N}^o$ and $'\m{N}^e$ (Figure \ref{fig:joinrules}B), as $'\m{N}^o$ has a changed ancestry and  $'\m{N}^e$ is even. The PDC is thus minimized if option A is always chosen. \\

% If the subset $'\m{N}^e$ consists of only two odd node sub-subsets $''\m{N}^o_0, ''\m{N}^o_1$, where $n_0, n_1$ are the joining nodes, the ancestry in $''\m{N}^o_0$ is preserved and $n_1$ is the subroot of $''\m{N}^o_1$. We see that the parities in all ancestors of $n_0$ are flipped. Let's consider the cases and find whether we can minimize the parity and delay calculation in $'\m{N}^{e}$.
%
% For case a), an even number of nodes of $'\m{N}^e$ is attached to $n^o$, and the ancestry in $'\m{N}^o$ hasn't changed. This means that the parities in $'\m{N}^o$ do not change per lemma \ref{lem:anynoderoot}, and the delays in $'\m{N}^o$ are still valid as per lemma \ref{lem:nodecalc_ancestrypath}. In $'\m{N}^e$, as the ancestry path has changed, we are certain to traverse $'\m{N}^e$ from the subroot $n^e$ to calculate the delays in this subset which is in the order of $S_{'\m{N}^e}$.
%
% In case b), as an odd number of nodes of $'\m{N}^o$ is attached to $n^e$, it means that parities of all ancestor of $n^e$ are flipped. As the ancestry in $'\m{N}^{o}$ has changed, we are certain to traverse $'\m{N}^o$ from the subroot $n^o$ to calculate the delays which is in the order of $S_{'\m{N}^o}$. The node parity changes in $'\m{N}^e$ will be dependent on the location of $n^e$ in the ancestry compared to $n^1$ and $n^2$, and all children nodes of these parity changes will have to recalculate their delays. Let's call the number of nodes needs to calculate parity and delays in $'\m{N}^e$ a value $S_e \leq S_{'\m{N}^e}$, leaving the total number of operations in the order of $S_e + S_{'\m{N}^o}$.
%
% For $'\m{N}^e$ consisting of two subsets, keeping track of the parity changes between $n^e$, $n^0$ and $n^1$ is still an easy task, and we might gain in minimization in operations in case b) compared to case a) for some value $S_e$ such that $S_e + S_{'\m{N}^o} < S_{'\m{N}^e}$. But as the number of subsets in $'\m{N}^e$ increases, the task of finding the ancestry paths of parity changes becomes analogous to traversing $'\m{N}^e$ entirely $S_e \rightarrow S_{'\m{N}^e}$. To simplify, we always choose case a.

From Lemmas \ref{lem:nodecalc_even} and \ref{lem:nodecalc_odd}, we can define a simple rule that determines how node-trees are joined.

\begin{definition}\label{def:joinbyparity}
  Let the \emph{join by parity} rule govern how to join node-trees in the event of clusters merging. For even-joins between two even or two odd node-trees, the parent and child node-trees can be picked at random. For odd-joins between nodes $n_j^e \in \nset^e, n_j^o \in \nset^o$, always make the even node-tree a child of the even node-tree, where $n_j^e$ is now the subroot of the subtree $\nset^e$.
\end{definition}
The \emph{join by parity} rule ensures that the parities and delays in $\nset^o$ are preserved and that only a partial calculation is needed related to the depth-first search from node $n_j^e$. Note the concept of a \emph{partial} calculation is rather redundant. Using these rules for the joins of node-trees, the parity and delay calculations are never calculated on a full node-tree except for the initial round. 

Recall from Definition \ref{def:nodeset} that the node-tree $\nset_j$ of cluster $c_j$ is stored by its root node at $c_j.n_r$, which sets the ancestry in the node-tree. In a join of two-node sets, the \emph{join by parity} rule requires to conditionally set the ancestry in the joined node set. This can simply done by connecting the node-trees with a new edge selecting the correct root node to be stored the merged cluster (see Algorithm \ref{algo:join}). Also due to the use of undirected edges, it is required to store the direction of the partial parity and delay calculation.

% \begin{theorem}\label{the:nodejoint}
%   The union of node-trees $\m{N}^\alpha, \m{N}^\beta$ on nodes $n^\alpha, n^\beta$ respectively is performed with $\codefunc{Join}(n^\alpha, n^\beta)$. If the join is between an even and an odd node-tree $\nset^e, \nset^o$ in the nodes $n^e, n^o$, $\codefunc{Join}(n^e, n^o)$ makes the node of the even set $n^e$ a child of the node of the odd set $n^o$. If the join is between two even or two odd node-trees, the choice is arbitrary.
% \end{theorem}
\begin{definition}
  Let us make a distinction between the \emph{final odd-join} between an odd node-tree $'\nset^o$ and an even node tree $'\nset^e$ to a joined node-tree $\nset$, and all others odd-joins that joined to $'\nset^e$ within the same round which we dub \emph{intermediate odd-joins}. 
\end{definition}

\begin{lemma}\label{lem:delaywhengrown}
  Redundant partial parity and delay calculations over even subtrees in intermediate odd-joins are prevented by applying the calculation directly before the growth of the cluster. 
\end{lemma}
\begin{proof}
  Consider the case when partial delay and parity calculations are initiated from a node $n_j^e \in \nset^e \subset \nset$ directly after the join of $\nset^e$ and $\nset^o$ to the joined node-tree $\nset$ while applying the \emph{join by parity} rule of Definition \ref{def:joinbyparity}. If there are many odd-joins (and even-joins) within the same round of growth, that at the end of round all joins to a single cluster with node-tree $\nset$, every odd-join will require the partial calculation over the even subtree. There may thus be many even subtrees where multiple partial calculations are performed within the same round before the final cluster $\nset$ is constructed. All but the final calculation will lead to the correct parities and delays in $\nset$. To circumvent any redundant calculations on the even subtrees of intermediate odd-joins, the partial calculation is suspended as much as possible, until just before a cluster is grown.
\end{proof}

Consider an example with 5 odd node-trees $\nset_1, ...,  \nset_5$ (Figure \ref{fig:redundantpdc}) that join to a single node-tree, where the partial calculation is applied directly after each join. The join of $\nset_1$ and $\nset_2$ to $\nset_{12}$ is an even-join and requires no partial calculation. The join of $\nset_{12}$ and $\nset_3$ is an odd-join, and we apply partial calculations in $\nset_{12}$. The join of $\nset_{123}$ and $\nset_4$ is an even-join and the join of $\nset_{1234}$ and $\nset_5$ is an odd-join, with partial calculations in $\nset_{1234}$. The earlier computation in $\nset_{12}$ is thus redundant. 

\input{tikzfigs/partialcalculations.tex}
% \begin{lemma}\label{lem:oddisevenodd}
%   An odd- node-tree $\nset$ that is the result of some joins must consist of an odd- subtree $'\nset^o$ and an even subtree $'\nset^e$, where the even subtree $'\nset^e$ may consist of smaller sub-subsets $''\nset$.
% \end{lemma}
% \begin{proof}
%   Just like some odd integer $z$ that is the sum of integers $x$ and $y$. If $x$ is odd, then $y$ must be even. This sum can also be of the odd integer $x$ and a set of even integers $\{y_1, y_1, ...\}$. 
% \end{proof}

The only task now is to store the subroot of the even subtree $n_j^e \in '\nset^e$ of the of the final odd-join, as this subroot is the starting point of the depth-first searches of the partial parity and delay calculation. For every odd-join between odd node-tree $'\m{N}^o$ and even node-tree $'\m{N}^e$ on nodes $'n_j^o, 'n_j^e$ to a cluster $c_j$, store the subroot $'n^e_j$ at the cluster as the \emph{undefined node subroot} $c_j.u$ (Algorithm \ref{algo:join}). If $c_j$ is selected for growth and it has an undefined node subroot $c_j.n_u$, we apply $\codefunc{Calcparity}(c_j.n_u)$ and $\codefunc{Calcdelay}(c_j.n_u)$ (Algorithms \ref{algo:calcparity}, \ref{algo:calcdelay}) to calculate parities and delays in undefined subtrees. We then call $\codefunc{Bloom}(c_j.n_r)$ (Algorithm \ref{algo:bloom}) to grow the cluster. 

% This data structure dynamically saves the root of the undefined part of a cluster to the root node. For any IO-join, we don't know yet whether another O-join will occur, thus each IO-join to cluster $''\nset^o$ is treated as a FO-join. For a IO-join, we thus also store the undefined subroot $u_1$ at the root $r_1=''n_r_{-1}$. If $''\nset^o$ joins with other clusters in subsequent E-join to cluster $'\nset^e$ and lastly the "real final" FO-join with $'\nset^o$ to $\nset^o$, we again store the undefined subroot $u_2='n_r^e$ at the new root of $r_2='n_r_{-1}$. Due to Lemma \ref{lem:nodecalc_odd}, it is certain that $u_2$ is an ancestor of $u_1$, and the PDC will traverse over all undefined regions of the set.

% \begin{theorem}\label{the:delayonce}
%   Undefined region of an odd cluster $\nset^o$ is defined as the subroot $u$ for which all children nodes including $u$ have undefined parities and delays, and is stored at root node $n^o_r$. PDC is performed for $n^o_r.u$ and its children before cluster $\nset^o$ is grown.
% \end{theorem}
\input{pseudocodes/join.tex}

\section{Pseudo-code}
Now we have the full description of the alteration of the Union-Find decoder, which we dub the \emph{Union-Find Balanced-Bloom} decoder. Recall from Theorem \ref{the:nodepmw} that the potential matching weight is only defined if a dynamic forest of clusters is maintained, and Recall from Section \ref{sec:ufperformance} that weighted growth improves the code threshold of the Union-Find Decoder. Thus the modification will be applied to the Dynamic-forest Bucket Union-Find decoder \ref{algo:dbuf}. 

In the Union-Find Balanced-Bloom decoder of Algorithm \ref{algo:ufbb}, partial parity and delay calculations are applied if a cluster $c_i$ has an undefined node subroot $c_i.n_u$, and \codefunc{Grow} (Algorithm \ref{algo:ufgrow}) is replaced with \codefunc{Ngrow} (Algorithm \ref{algo:bbgrow}). Futhermore, when iterating over the edges of the merging list $\m{L}_m$, if the vertex-tree roots of the supporting vertices do not belong to the same cluster, it either means that a new vertex is added to the cluster, or that two clusters are merged. In the first case, the new vertex is added to the node, whereas in the second case, two node-trees are joined. To be able to differentiate between these cases, we need to additionally store the node $n$ containing the vertex $v\in v.\vset$ at the vertex as $v.n$. With this data structure, two node-trees have to be joined on $v.n$ and $u.n$ if they both exist. Otherwise, the node is to be saved to the newly added vertex. 

\input{pseudocodes/ufbb.tex}

\section{Complexity of Balanced-Bloom}\label{sec:ufbbcomplexity}

In this section, we will find the time complexity of the Union-Find Balanced-Bloom decoder (Algorithm \ref{algo:ufbb}) through using an analytic approach. As the Union-Find Balanced-Bloom decoder is modification of the Dynamic-forest Bucket Union-Find decoder (Algorithm \ref{algo:dbuf}), which is known to have a time complexity of $\m{O}(n\alpha(n))$ (Section \ref{sec:ufcomplexity}), we will only consider the added complexity that is made by the modification. The additional contribution to the complexity to the Dynamic-forest Bucket Union-Find decoder can be divided into two parts. First is the contribution by the depth-first searches of \codefunc{Calcparity} and \codefunc{Calcdelay}, the parity and delay calculations, which we dub the \emph{PDC complexity}, treated in Section \ref{sec:pdfcomplexity}. The second contribution will be caused the replacement of \codefunc{Grow} with \codefunc{Ngrow}, where now an additional depth-first search of the node-tree of every cluster needs to be performed to access its boundary edges stored at the nodes and grow them with \codefunc{Bloom}. We call this second contribution the \emph{bloom complexity}, which is detailed in Section \ref{sec:bloomcomplexity}.

\subsection{PDC complexity}\label{sec:pdfcomplexity}
Recall from Lemmas \ref{lem:nodecalc_even} and \ref{lem:nodecalc_odd} that the node parities and delays within become undefined in the entire node-tree after an even-join, and that partial parity and delay calculations are to be performed in the even subtree after an odd-join. Lemma \ref{lem:delaywhengrown} proves that these calculations can be limited to the even subtrees in \emph{final odd-joins}. The size of the even subtrees in these final odd-joins, multiplied by the number of final odd-join operations thus estimates the cost of the parity and delay calculations. 
%We will take a top-down approach to find these estimates, where we retrace the ancestor node-trees in their join operations in what we call the \emph{fragmentation} of $\nset$.
\begin{definition}\label{def:npdc}
  Let $N_{PDC}$ of Equation \eqref{eq:npdc} be the total number of nodes travelled during depth-first searches of the parity and delay calculations.
\end{definition}

For every odd node-tree $\nset^o$, it may be the result by many joins of smaller \emph{ancestral} node-trees in some previous growth iteration. Before $\nset^o$ is grown, a partial calculation is performed on the even subtree $'\nset^e$ of the final odd-join of its ancestral node-trees. This calculation is related to two depth-first searches of the subtree from undefined node subroot $r_u$. The cost of the calculation is thus proportional to $|'\nset^e|$, and counts towards $N_{PDC}$. Subtree $'\nset^e$ may itself be the result of many intermediate odd-joins and even-joins in some previous growth iteration. But as these joins do not add towards $N_{PDC}$, it is not crucial to know which joins have occurred. What matters to the $N_{PDC}$ count is to know the entire set of odd subsets $''\nset^o$ that constructs $'\nset^e$, as each of $''\nset^o$ is subjected to a partial calculation from their undefined node subroots or in their even subtrees when they are grown.

\begin{definition}\label{def:fragmentation}
  Let the \emph{fragmentation} of a node-tree $\pre{k-1}\nset^o$ split $\pre{k-1}\nset^o$ into a set of its ancestral node-trees $\m{F}_k = \{\pre{k}\nset_1, \pre{k}\nset_2, ...\}$, and resembles the inverse of a join operation. Here the prefix $k$ indicates the \emph{ancestral generation}, where a larger $k$ is equivalent to a more distant ancestor set of smaller subtrees. As the size of the even node-tree in the final odd-join counts towards $N_{PDC}$, we make the distinction between \emph{partial fragmentations} $f_e$ and $f_o$. Partial fragmentation $f_o$ on an odd node-tree is equivalent to the inverse of the final odd-join to node-tree $\pre{k-1}\nset^o$, where
  \begin{equation}\label{eq:pfe}
    f_o(\pre{k-1}\nset^o) = \m{F}^o_k = \{\pre{k}\nset^e_{-1}, \pre{k}\nset^o_0 \}.
  \end{equation}
  Partial fragmentation $f_e$ on an even node-tree is equivalent to the combination of all intermediate odd-joins and even-joins that join to $\pre{k}\nset^e_{-1}$, with
  \begin{equation}\label{eq:pfo}
    f_e(\pre{k}\nset^e_{-1}) = \m{F}^e_k=\{\pre{k}\nset^{o}_1,...,\pre{k}\nset^o_{k_f}\} \hspace{1em} | \hspace{1em} k_f = 2i, i \in \mathbb{N}^*,
  \end{equation}
  where $\pre{k}\nset^e_{-1}$ is split into $k_f$ odd ancestral subtrees within the same ancestral generation. Let $k_f$ be the \emph{partial fragmentation number}. Let us call the 2 fragmentations $f_o, f_e$ of a odd node-tree$\pre{k-1}\nset^o$ into a set of odd node-trees $\m{F}_k = \{\pre{k}\nset^o_0,..., \pre{k}\nset^{o}_{k_f}\}$ a \emph{fragmentation step} $f$. Note that a fragmentation step is only possible on a node-tree $\nset^o$ with $|{\nset^o}| \geq 3$, in which case the resulting subsets have size 1.
  \begin{equation}\label{eq:fstep}
    f(\pre{k-1}\nset^o) = \m{F}_k = f_e(f_o(\pre{k-1}\nset^o)) = \{\pre{k}\nset^o_0,...,\pre{k}\nset^{o}_{k_f}\} \hspace{.3cm} | \hspace{.3cm} \abs{{\pre{k}\nset^o_j}} \geq 3
  \end{equation}
\end{definition}

\input{tikzfigs/fragmentation.tex}

If partial fragmentation function $f_o$ is called on a set of node-trees $f_o(\{\nset^o, \nset^e, ...\})$, it fragments all odd node-trees in the set, and $f_e$ fragments all even node-trees. Along these lines, the entire set of odd node-trees $\m{F}_k$ can undergo the another fragmentation step into odd subsets, resulting in a second set ancestral node-trees $\m{F}_{k+1}$. We can do this some $p$ times on $\pre{0}\nset^o$, where we have set $k-1=0$, until our resulting set of node-trees $\m{F}_{p}$ consists only of smallest possible node subsets $\pre{p}\nset^o$ where $S|\pre{p}\nset^o|=1$. 

\begin{definition}\label{def:fullfrag}
  Let the series of all $p$ fragmentation steps $f$ on $\pre{0}\nset^o$ be the \emph{full fragmentation} $F$, with
  \begin{equation}\label{eq:fullfrag}
    F(\pre{0}\nset^o) = \underbrace{f(f(...f(\pre{0}\nset^o)))}_\text{p times} = \{\pre{p}\nset^{o}_1, \pre{p}\nset^{o}_2,...,\pre{p}\nset^{o}_{N_\sigma} \} \hspace{.3cm} | \hspace{.3cm} \abs{\pre{p}\nset^{o}_i} = 1.
  \end{equation}
\end{definition}

To find the worst-case complexity, we maximize $N_{PDC}$ or the cost of the partial calculations during the construction the node-trees on the lattice. Let us assume the worst-case when there are a maximal number of nodes in the node-trees just before the last round of growth. As the lattice is maximally occupied, this is a single odd node-tree $\pre{0}\nset^o$ in which a partial calculation is performed as part of the last round of growth. Node-tree $\pre{0}\nset^o$ has a maximal number of nodes if $|n.\vset=1$ for all nodes $n$ in $\pre{0}\nset^o$. Thus on a lattice of $N=|\vset|$ vertices, the node-tree $\pre{0}\nset^o$ has a maximal 
\begin{equation}\label{eq:limitnsetsize}
  \abs{\pre{0}\nset^o} \leq N
\end{equation}
nodes. As the partial calculation is only executed on the even subtrees, $N_{PDC}$ is the sum of even node-trees sizes $|\pre{k}\nset^e|$, in all partial fragmentation sets $\m{F}^o_{k}$, during all fragmentation steps $k=[1,...,p]$, in the full fragmentation of $F(\pre{0}\nset^o)$. We add the factor 2 in Equation \eqref{eq:npdc} as both the parity calculation and delay calculations requires its own depth-first search. The sequence of fragmentations that maximizes the even node-tree sizes maximizes $N_{PDC}$.
% The worst-case delay complexity is computed by maximizing $N_{PDC}$ of the full fragmentation of $\pre{0}\nset^o$ with $S_{\pre{0}\nset^o} = N/2-1$.
\begin{equation}\label{eq:npdc}
  N_{PDC} = 2\sum_{k=1}^{p}{ \sum_j{ \left\{ \abs{\pre{k}\nset_j^e} \big| \pre{k}\nset_j^e \in \m{F}^o_k \right\} } }
  \hspace{1em} \bigg| \hspace{1em} \m{F}_k^o \text{ during } F(\pre{0}\nset^o).
\end{equation}

\begin{definition}\label{lem:fragratio}
  Let the partial fragmentation ratio $R$ be the relative sizes of a ancestral node-tree $\nset_i$ and the fragmented node-tree $\nset$.
  \begin{equation}\label{eq:fragratio}
    R_i = \frac{\abs{\nset_f}}{\abs{\nset}}
  \end{equation}
\end{definition}
In $f_e$ there are a set of partial fragmentation ratios $\{r_{-1}, r_0\}$, and in $f_o$ are a set of partial fragmentation ratios $\{r_1,...,r_{k_f}\}$, where
\begin{align}
  r_{-1} +  r_0 &= 1 \\
 \sum_{i=1}^{k_f}{r_i} &= 1. 
\end{align}

The problem of finding the sequence of even ancestral node-tree sizes to maximize the value of $N_{PDC}$ now becomes finding the partial fragmentation number $k_f$ and the set of partial fragmentation ratios $\{r_{-1},..., r_{k_f}\}$.  

\begin{lemma}\label{lem:sumevenkf}
  For the same partial fragmentation ratios $\{r_{-1}, r_0\}$ in $f_o$, the sum of even ancestral node-tree sizes after a fragmentation step is not dependent on $k_f$ (see Figure \ref{fig:fragcorrect}). 
\end{lemma}
\begin{proof}
  Let us consider an even node-tree $\pre{k}\nset^e$ that is first partially fragmented by $f_e$ to $\m{F}^e_k$. The fragmentation set $\m{F}^e_k$ is then partially fragmented by $f_o$ to $\m{F}_{k+1}^o$. Let us consider the two cases when $k_f=2$ and $k_f=4$. For $k_f=2$, the partial fragmentation $f_e$ splits $\pre{k}\nset^e$ into two odd ancestral node-trees in $\m{F}^e_k$ and four node-trees in $\m{F}_{k+1}^o$.
  % Let the size of $\pre{k-1}\nset^e$ be $|\pre{k-1}\nset^e| = K$. To find $n_o$, let us consider two cases where $n_o = 1$ or $n_o=2$. If an even node-tree $\pre{k-1}\nset^e$ is fragmented with $k_f=2$, a fragmentation step $f(\pre{k-1}\nset^e)=f_o(f_e(\pre{k-1}\nset^e))$ produces the following partial fragmentation sets:
  \begin{eqnarray*}
  % \nonumber % Remove numbering (before each equation)
    f_e(\pre{k}\nset^e)_{k_f = 2} 
    =& \m{F}^e_{k}|_{k_f = 2} 
    =& \{ \pre{k} \nset^{o}_1, \pre{k} \nset^{o}_2\}  \\
    f_o(\m{F}^e_{k}|_{k_f = 2}) 
    =& \m{F}^o_{k+1}|_{k_f = 2} 
    =& \left\{ \{\pre{k+1}\nset^{o}_{0}, \pre{k+1}\nset^{e}\}^o_1 , \{\pre{k+1}\nset^{o}_{0}, \pre{k+1}\nset^{e} \}^o_2 \right\}
  \end{eqnarray*}
  The ratios of the sizes of fragmented node-trees in $f_e$ are
  \begin{equation*}
    \frac{\abs{\pre{k} \nset^{o}_1}}{\abs{\pre{k}\nset^e}} = r_1, \hspace{2em}
    \frac{\abs{\pre{k} \nset^{o}_2}}{\abs{\pre{k}\nset^e}} = r_2, 
  \end{equation*}
  where $ r_1 + r_2 = 1$. The ratios of the sizes of fragmented node-trees in $f_o$ are
  \begin{equation*}
    \frac{\abs{\pre{k+1}\nset^{o}_0|^o_1}}{\abs{\pre{k} \nset^{o}_1}} = 
    \frac{\abs{\pre{k+1}\nset^{o}_0|^o_2}}{\abs{\pre{k} \nset^{o}_2}} = r_0, \hspace{2em}
    \frac{\abs{\pre{k+1}\nset^{e}  |^o_1}}{\abs{\pre{k} \nset^{o}_1}} = 
    \frac{\abs{\pre{k+1}\nset^{e}  |^o_2}}{\abs{\pre{k} \nset^{o}_2}} = r_{-1},  
  \end{equation*}
  where $r_0 + r_{-1} = 1$. The sum of the sizes of even node-trees in the odd partial fragmentation set $\m{F}^o_{k+1}$ is thus
  \begin{equation*}
    r_1 r_{-1} \abs{\pre{k}\nset^e} + r_2 r_{-1} \abs{\pre{k}\nset^e} = (r_1 + r_2) r_{-1} \abs{\pre{k}\nset^e} = r_{-1} \abs{\pre{k}\nset^e}
  \end{equation*}

  For $k_f = 4$, the partial fragmentation sets are
  \begin{eqnarray*}
  % \nonumber % Remove numbering (before each equation)
    f_e(\pre{k}\nset^e)_{k_f = 4} 
    =& \m{F}^e_{k}|_{k_f = 4} 
    =&\{ \pre{k}\nset^{o}_1, \pre{k}\nset^{o}_2,  \pre{k}\nset^{o}_3, \pre{k}\nset^{o}_4\},  \\
    f_o(\m{F}^e_{k}|_{k_f = 4}) 
    =& \m{F}^o_{k+1} |_{k_f = 4} 
    =& \big\{      \{ \pre{k+1}\nset^{o}_0, \pre{k+1}\nset^e\}^o_1, 
                    \{ \pre{k+1}\nset^{o}_0, \pre{k+1}\nset^e\}^o_2, \\
    && \hspace{3em} \{ \pre{k+1}\nset^{o}_0, \pre{k+1}\nset^e\}^o_2,
                    \{ \pre{k+1}\nset^{o}_0, \pre{k+1}\nset^e\}^o_4 \big\}.
  \end{eqnarray*}
  The ratios of the sizes of fragmented node-trees in $f_e$ are
  \begin{equation*}
    \frac{\abs{\pre{k} \nset^{o}_1}}{\abs{\pre{k}\nset^e}} = q_1, \hspace{2em}
    \frac{\abs{\pre{k} \nset^{o}_2}}{\abs{\pre{k}\nset^e}} = q_2, \hspace{2em}
    \frac{\abs{\pre{k} \nset^{o}_3}}{\abs{\pre{k}\nset^e}} = q_3, \hspace{2em}
    \frac{\abs{\pre{k} \nset^{o}_4}}{\abs{\pre{k}\nset^e}} = q_4, 
  \end{equation*}
  where $ q_1 + q_2 + q_3 + q_4 = 1$. The ratios of the sizes of fragmented node-trees in $f_o$ are
  \begin{equation*}
    \frac{\abs{\pre{k+1}\nset^o_0|^o_1}}{\abs{\pre{k} \nset^{o}_1}} = 
    \frac{\abs{\pre{k+1}\nset^o_0|^o_2}}{\abs{\pre{k} \nset^{o}_2}} = 
    \frac{\abs{\pre{k+1}\nset^o_0|^o_3}}{\abs{\pre{k} \nset^{o}_3}} = 
    \frac{\abs{\pre{k+1}\nset^o_0|^o_4}}{\abs{\pre{k} \nset^{o}_4}} = r_0,
  \end{equation*}
  and 
  \begin{equation*}
    \frac{\abs{\pre{k+1}\nset^e|^o_1}}{\abs{\pre{k} \nset^{o}_1}} = 
    \frac{\abs{\pre{k+1}\nset^e|^o_2}}{\abs{\pre{k} \nset^{o}_2}} = 
    \frac{\abs{\pre{k+1}\nset^e|^o_3}}{\abs{\pre{k} \nset^{o}_3}} = 
    \frac{\abs{\pre{k+1}\nset^e|^o_4}}{\abs{\pre{k} \nset^{o}_4}} = r_{-1},  
  \end{equation*}
  where $r_0 + r_{-1} = 1$. The sum of the sizes of even node-trees in  the odd partial fragmentation set $\m{F}^o_{k+1}$ is thus
  \begin{equation*}
    q_1 r_{-1} \abs{\pre{k}\nset^e} + q_2 r_{-1} \abs{\pre{k}\nset^e} + q_3 r_{-1} \abs{\pre{k}\nset^e} + q_4 r_{-1} \abs{\pre{k}\nset^e} = (q_1 + q_2 + q_3 + q_4 ) r_{-1} \abs{\pre{k}\nset^e} = r_{-1} \abs{\pre{k}\nset^e}. 
  \end{equation*}
  This is true for any $k_f = 2i, i\in \mathbb{N}^*$. 
\end{proof}

\begin{lemma}\label{lem:equalevensum}
  The sum of even node-tree sizes in every fragmentation step $k$ is only dependent on partial fragmentation ratios $\{r_{-1}, r_0\}$. 
  \begin{equation}\label{eq:equalevensum}
    \sum_j{ \left\{ \abs{\pre{k}\nset_j^e} \big| \pre{k}\nset_j^e \in \m{F}^o_k \right\} } = \text{constant}
  \hspace{1em} \bigg| \hspace{1em} \forall \m{F}_k^o \text{ during } F(\pre{0}\nset^o).
  \end{equation}
\end{lemma}
\begin{proof}
  Consider an odd node-tree $\pre{k-1}\nset^o$ that is partially fragmented as 
  \begin{eqnarray*}
    f_o(\pre{k-1}\nset^o) &= \m{F}^o_k      &= \{\pre{k}\nset^e_{-1}, \pre{k}\nset^o_0 \} \\
    f_e(\m{F}^o_k)        &= \m{F}^e_k      &= \left\{ \{\pre{k}\nset^o_i\ | i \in [1,..,k_f] \}^e_{-1}, \pre{k}\nset^{o}_0 \right\} \\
    f_o(\m{F}^e_k )       &= \m{F}^o_{k+1}  &= \left\{ \left\{ \{\pre{k+1}\nset^e_{-1}, \pre{k+1}\nset^o_0\}_i^o | i \in [1,..,k_f] \right\}^e_{-1}, \left\{\pre{k}\nset^e_{-1}, \pre{k}\nset^o_0 \right\}^{o}_0 \right\}
  \end{eqnarray*}

  The sum of even node-tree sizes in $\m{F}^o_k$ is simply the size of $\pre{k}\nset^e_{-1}$ and is equal to
  \begin{equation*}
    \sum_j{ \left\{ \abs{\pre{k}\nset_j^e} \big| \pre{k}\nset_j^e \in \m{F}^o_k \right\} } = \abs{\pre{k}\nset^e_{-1}} = r_{-1}\abs{\pre{k-1}\nset^o}. 
  \end{equation*}

  The sum of even node-tree sizes in $\m{F}^o_{k+1}$ can be divided into two parts. The first part is the partial fragmentations $f_e f_o$ of $\pre{k}\nset^e_{-1}$, which we know from Lemma \ref{lem:sumevenkf} is $r_{-1}|\pre{k}\nset^e_{-1}|$ regardless of the choice for $k_f$. The second part is the partial fragmentation $f_o$ of $\pre{k}\nset^o_0$, which is $r_{-1}|\pre{k}\nset^o_0|$. Hence the sum is
  \begin{equation*}
    \sum_j{ \left\{ \abs{\pre{k}\nset_j^e} \big| \pre{k}\nset_j^e \in \m{F}^o_{k+1} \right\} } = r_{-1} \left( \abs{\pre{k}\nset^e_{-1}} + \abs{\pre{k}\nset^o_0} \right) = r_{-1}\abs{\pre{k-1}\nset^o}. 
  \end{equation*}
\end{proof}

\begin{theorem}\label{the:fragnumber}
  For the fragmentation number $k_f=2$, $N_{PDC}$ of Definition \ref{def:npdc} and Equation \eqref{eq:npdc} is maximized (see Figure \ref{fig:fragexamples}). 
\end{theorem}
\begin{proof}
  The sum of even node-tree sizes in each fragmentation step is constant per Lemma \ref{lem:equalevensum}. Thus \eqref{eq:npdc} is maximized by having as many fragmentations steps as possible, or a largest possible $p$.  As $k_f$ increases the number of odd node-trees in each fragmentation step $f_o$, the average size of these odd node-trees have decreased. Consequently, the node-tree size decreases faster towards the minimum size of 3 nodes as more fragmentation steps are applied (Equation \eqref{eq:fstep}). As the sum of even node-tree sizes in each fragmentation step is the same, increasing $k_f$ decreases the number of fragmentation steps: 
  \begin{equation}
    p \propto \frac{1}{k_f}.
  \end{equation}
   Hence $N_{PDC}$ is maximized for minimal value of $k_f$ which is $k_f = 2$.
\end{proof}

\input{tikzfigs/fragnumber.tex}

The search for the fragmentation ratios has now been reduced to finding $\{r_{-1}, r_0\}$ of $f_o$ and $\{r_1, r_2\}$ of $f_e$ since $k_f = 2$. A partial fragmentation $f_e$ of $\pre{k}\nset^e_{-1}$ and fragmentation step $f$ of $\pre{k-1}\nset^o$ are now
\begin{eqnarray}
  f_e(\pre{k}\nset^e_{-1})  &= \m{F}^e_k  &=\{\pre{k}\nset^{o}_1,\pre{k}\nset^o_2\} \label{eq:newpfe}\\
  f(\pre{k-1}\nset^o)       &= \m{F}_k    &= \{\pre{k}\nset^o_0, \pre{k}\nset^o_1, \pre{k}\nset^o_1\}. \label{eq:newfstep}
\end{eqnarray}
The sizes of the ancestral odd node-trees in a fragmentation step $f$ are related to the joined node-tree by
\begin{equation}
  \frac{\abs{\pre{k}\nset^o_0}}{\abs{\pre{k-1}\nset^o}} = R_0, \hspace{2em}
  \frac{\abs{\pre{k}\nset^o_1}}{\abs{\pre{k-1}\nset^o}} = R_1, \hspace{2em}
  \frac{\abs{\pre{k}\nset^o_2}}{\abs{\pre{k-1}\nset^o}} = R_2,
\end{equation}
where
\begin{align}
  \nonumber R_0 &= r_0\\
            R_1 &= r_{-1}r_1\\
  \nonumber R_2 &= r_{-1}r_2\\
  R_0 + R_1 + R_2 &= 1. \label{eq:bigratios}
\end{align}

This fragmentation number does not come unexpected. If $k_f=2$, a fragmentation $f_e$ outputs two ancestral node-trees. This is equivalent to a single even-join. If $k_f>2$, the fragmentation $f_e$ will be equivalent to a number of even-joins and intermediate odd-joins. Recall from Lemma \ref{lem:delaywhengrown} that the partial calculation of every intermediate odd-join is skipped. Thus these partial calculations are "lost" in the maximization of $N_{PDC}$. 

Let us now try to maximize $N_{PDC}$ of Equation \eqref{eq:npdc} not from the perspective of fragmentations, but from the perspective of cluster growth. During a growth iteration, some $N_v$ vertices are added to the cluster $c_j$ and some other clusters merge with $c_j$ that also require the join of their respective node-trees. If no join operations occur, the node-tree stays unchanged, and the cluster is allowed to continue to grow without delay calculations per Lemma \ref{lem:calconce}. To maximize $N_{PDC}$, $N_v$ must be minimized, as every added vertex here is one that could have been part of a node in some other node-tree, and thus does does not add to $N_{PDC}$. 

\begin{theorem}\label{the:fragratio}
  For the fragmentation ratios $R_0 = R_1 = R_2 = \frac{1}{3}$, $N_{PDC}$ of Definition \ref{def:npdc} and Equation \eqref{eq:npdc} is maximized in a Union-Find Balanced-Bloom decoder with weighted growth (see Section \ref{sec:bucketwg}). 
\end{theorem}
\begin{proof}
  Take the partial fragmentation $f_o$ of $\pre{k-1}\nset^o$ of Equation \eqref{eq:pfo} and $f_e$ of Equation \eqref{eq:newpfe}, which are equivalent to a final odd-join between $\nset^e_{-1}, \nset^o_0$ and even-join between $\nset^o_1, \nset^o_2$, respectively. 
  
  For $f_e$ that is equivalent to the even-join to even-parity cluster $c_{-1}$ between the odd-parity clusters $c_1, c_2$ with node-trees $\nset^o_1, \nset^o_2$, the clusters must have relative equal vertex-tree sizes 
  \begin{equation*}
    \abs{\vset_1} \approx \abs{\vset_2}.
  \end{equation*}
  If not, clusters $c_1, c_2$ may be allowed to grow multiple iterations before merging, sorted by weighted growth. In each iteration some $N_v$ vertices are added tot the cluster. Let the growth iteration in which the even-join occurred be labeled as $i_e$
  
  For $f_o$ equivalent to the final odd-join between even $c_{-1}$ and odd $c_0$, the final odd-join must strictly occur after the even join of $f_e$. This odd-join can either by initiated by odd-parity $c_0$ in some growth iteration $i_o > i_e$, when $c_2$ is the only odd-parity cluster, or initiated by either $c_1$ or $c_2$ in growth iteration $i_o = i_e$ (see Figure \ref{fig:fragfratio}). Determined by weighted growth, the vertex-tree sizes are related as
  \begin{equation*}
    \abs{\vset_0} \geq \abs{\vset_1} \approx \abs{\vset_2}.
  \end{equation*}
  Recall from equation \eqref{eq:sets} that $|\nset| \leq |\vset|$. We assume the largest possible node-tree size $|\nset| = |\vset|$ to find that 
  \begin{equation*}
    \abs{\nset^o_0} \geq \abs{\nset^o_1} \approx \abs{\nset^o_2},
  \end{equation*}
  and hence
  \begin{equation*}
    R_0 \geq R_1 \approx R_2,
  \end{equation*}
  To maximize $N_{PDC}$, we want to maximize $\abs{\nset^e_{-1}} = \abs{\nset^o_1} + \abs{\nset^o_2}$ or $R_1 + R_2$. Since \eqref{eq:bigratios}, $R_0$ must be as small as possible, and thus $R_0 = R_1 = R_2 = \frac{1}{3}$. 
\end{proof}

\input{tikzfigs/fragratio.tex}

The last unknown parameter for the maximization of $N_{PDC}$ in Equation \eqref{eq:npdc} is $p$, the total number of fragmentation steps. If we assume that in every growth step not a single non-node vertex is added $N_v = 0$, the full fragmentation of odd node-tree $\pre{0}nset^o$ is just the continuous division of the set in 3 parts per Theorem \ref{lem:fragratio}, which can be calculated easily.
\begin{equation}\label{eq:numfrag}
  p \leq \log_3(\abs{\pre{0}\nset^o})
\end{equation}
In every partial fragmentation set $\m{F}^o_k$, the sum of even node-tree sizes is 
\begin{equation}\label{eq:sumevensetsize}
  \sum_j \left\{ \abs{\pre{k}\nset_j^e} \big| \pre{k}\nset_j^e \in \m{F}^o_k \right\} \leq \frac{2}{3}\abs{\pre{0}\nset^o},
\end{equation}
as $R_1+R_2 = \frac{2}{3}$ per Theorem \ref{the:fragratio} and this value is constant for every fragmentation step is constant per Lemma \ref{lem:equalevensum}. This is an inequality as we have assumed $|\nset| = |\vset|$ and $N_v=0$ in Theorem \ref{the:fragratio}. Filling in equation \eqref{eq:numfrag} and \eqref{eq:sumevensetsize} in \eqref{eq:npdc}, we find that
\begin{eqnarray}
% \nonumber % Remove numbering (before each equation)
\nonumber  N_{PDC}  &\leq& \sum_{k=1}^{p} \sum_j \left\{ \abs{\pre{k}\nset_j^e} \big| \pre{k}\nset_j^e \in \m{F}^o_k \right\}. \\
\nonumber           &\leq& \sum_{k=1}^{\log_3(\abs{\pre{0}\nset^o})} \frac{2}{3}\abs{\pre{0}\nset^o} \\
                    &\leq& \frac{2}{3}\abs{\pre{0}\nset^o}\log{\abs{\pre{0}\nset^o}}
\end{eqnarray}

Recall from Equation \eqref{eq:limitnsetsize} that the node-tree size of set is bounded by the lattice size $|\pre{0}\nset^o| \leq N$. The worst-case time complexity of the delay computation is thus bounded by $\m{O}(N\log{N})$. The average-case complexity is even lower as it is quite certain that not all vertices are nodes such that $|\nset| < |\vset|$ and $N_v \neq 0$.

\subsection{Bloom complexity}\label{sec:bloomcomplexity}

To grow a cluster represented by a node-tree $\nset$, a depth-first search is performed on the node-tree to iterate over each boundary list that are stored at the nodes. 
\begin{definition}\label{def:nbloom}
  Let the total number of times nodes are bloomed with \codefunc{Bloom} be $N_{bloom}$.
\end{definition}

Similar to the previous section we make the assumption of a maximum number of nodes on the lattice where in each cluster $|\nset| = |\vset|$ and $V_v = 0$. For a fragmentation step of $f(\pre{k-1}\nset^o)$ to $\{\pre{k}\nset^o_0, \pre{k}\nset^o_1, \pre{k}\nset^o_2\}$, $N_{bloom}$ is maximized if all three ancestral node-trees are grown. As the growth of every set $\nset$ adds $|\nset|$ to $N_{bloom}$, the total number of bloom can be found similarly to $N_{PDC}$ in Equation \eqref{eq:npdc}. The sum is now on all odd node-tree sizes in all $p$ fragmentation steps $\m{F}_k$: 
\begin{equation}\label{eq:nnode}
  N_{bloom} \leq \sum^{p}_{k=1}\sum_j \left\{ \abs{\pre{k}\nset^o_j} \big| \pre{k}\nset^o_j \in \m{F}_k \right\}
\end{equation}
For a full fragmentation of $\nset$ of size $S_\nset$, the sum of all set sizes in each fragmentation set $\m{F}$ is
\begin{equation}\label{eq:sumsetsfrag}
  \sum_j \left\{ \abs{\pre{k}\nset_j} \big| \pre{k}\nset^o_j \in \m{F}_k \right\} = \abs{\pre{0}\nset^o}.
\end{equation}
By filling in $p$ from \eqref{eq:numfrag}, we find that
\begin{eqnarray}
% \nonumber % Remove numbering (before each equation)
  \nonumber N_{bloom} &\leq& \sum^{p}_{k=1}\sum_j \left\{ \abs{\pre{k}\nset^o_j} \big| \pre{k}\nset^o_j \in \m{F}_k \right\} \\
  \nonumber           &\leq& \sum_{k=1}^{\log_3{\abs{\pre{0}\nset^o}}} \abs{\pre{0}\nset^o} \\
                      &\leq& \abs{\pre{0}\nset^o}\log_3{\abs{\pre{0}\nset^o}},
\end{eqnarray}
which again corresponds to a worst-case time complexity that is bounded by $\m{O}(N\log{N})$.

\section{Boundaries}\label{sec:ufbbbound}
For surfaces with boundaries, we introduced the concept of \emph{open vertices} $\vset_\omega$ that in contrast to normal vertices are not equivalent to stabilizers, measurements or ancillary qubits (Section \ref{sec:surface_planar}). During formation of the spanning forest $\m{T}_\m{R}$ of a cluster, we must make sure that $\m{T}_\m{R}$ does not contain more than 1 element of the set of boundary vertices $\vset_\omega$, as multiple elements of $\vset_\omega$ is equivalent to a cycle (Section \ref{sec:peelingbound}).
\begin{definition}\label{def:boundarynode}
  Let a boundary-node $b$ denote a node that is seeded in an open-vertex $v in \vset_\omega$. 
\end{definition}
The addition of boundaries requires a new type of node element, the \emph{boundary node} $n$, that is exclusive to boundary vertices of $\vset_\omega$, and are initiated on a boundary vertex if a cluster grows into the boundary. Recall from Section \ref{sec:peelingbound} that there can be only 1 boundary vertex in $\vset$. For this reason there can be only one boundary node in $\nset$. As a result, a boundary node will always be a trailing node in $\nset$ with no children, and will never be the root node. However, the always-trailing boundary node  always has parity 1, as a matching with the boundary is equally valid as a matching with another syndrome. The addition of boundary nodes just requires a small alteration to algorithm \ref{algo:calcparity}.
\input{pseudocodes/calcparitybound.tex}

For a surface containing $N$ qubits, the number of boundary elements scales with $\sqrt{N}$. The number of node elements is thus bounded by $N + \sqrt{N}$. The added complexity due to the boundary elements will therefore not exceed some linear factor and remains the same as previously computed.

\section{Erasure noise}\label{sec:ufbberasure}

The inspiration for the Union-Find decoder is the Peeling decoder (Section \ref{sec:peelingdecoder}), that only accounted for \emph{erasure} errors. As the Union-Find Balanced-Bloom decoder is a modification of the Union-Find decoder, we naturally needs to make sure that it can also solve erasure errors.

To account for these erasures, we must construct the node-trees for these initial erasure clusters. We can easily check that for an erasure-cluster, the potential matching for every neighboring vertex is different. Every vertex in the cluster is therefore a node in $\nset$, where each syndrome-vertex is a syndrome-node $\sigma$, and every other vertex is a linking-node $l$. Note that if the erasure is connected to the boundary, we need to make sure that only a single edge is connected to the boundary, where the single boundary vertex in the cluster naturally is a boundary node $b$. After constructing these initial clusters and node-trees, we can proceed to the Union-Find Balanced Bloom decoder.  

\section{Performance}

\begin{table}[htpb]
  \centering
  \begin{tabularx}{\textwidth} { | R{1} || C{1.5} | C{.5} | C{1.5} | C{.5} | }
   \hline
   & \multicolumn{2}{c|}{Independent noise}& \multicolumn{2}{c|}{Phenomenal noise} \\
   \hline
   & $p_{th}$ & $k_C$ & $p_{th}$ & $k_C$ \\
   \hhline{|=||=|=|=|=|}
   Toric code & $0.10229 \pm 0.00007$ & $0.7312$ & $0.02846 \pm 0.00003$ & $0.9165$ \\
   \hline
   Planar code  & $0.9927 \pm 0.0001$ & $0.8689$ & $0.02711 \pm 0.00006$ & $0.9480$ \\
  \hline
  \end{tabularx}
  \caption{Simulation results for the Union-Find Balanced-Bloom decoder. $L = 8:8:64, L=8:4:24$}\label{tab:ufbblow}
\end{table}

\begin{table}[htpb]
  \centering
  \begin{tabularx}{\textwidth} { | R{1} || C{1.5} | C{.5} | C{1.5} | C{.5} | }

   \hline
   & \multicolumn{2}{c|}{Independent noise}& \multicolumn{2}{c|}{Phenomenal noise} \\
   \hline
   & $p_{th}$ & $k_C$ & $p_{th}$ & $k_C$ \\
   \hhline{|=||=|=|=|=|}
   Toric code & $0.1007 \pm 0.0001$ & $0.769 $ & $0.0278 \pm 0.0003$ & $0.941$ \\
   \hline
   Planar code  & $0.9615 \pm 0.0004$ & $0.904$ &$0.02455 \pm 0.0004$ & $0.982$ \\
  \hline
  \end{tabularx}
  \caption{Simulation results for the Union-Find Balanced-Bloom decoder $L = 72:8:96, L=28:4:44$}\label{tab:ufbbhigh}
\end{table}


\begin{figure}[htbp]
  \centering
  % \begin{subfigure}[b]{\textwidth}
  %   \begin{adjustbox}{Clip=0 1em 0 0}
  %   \input{pgfplots/threshold_ufbb_toric_2d_full.pgf}
  %   \end{adjustbox}
  %   \caption{All simulations.}
  % \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    \begin{adjustbox}{Clip=0 1em 0 0}
      \input{pgfplots/threshold_ufbb_toric_2d_short.pgf}
    \end{adjustbox}
    \caption{Simulations around threshold.}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    \begin{adjustbox}{Clip=0 1em 0 0}
      \input{pgfplots/threshold_ufbb_toric_2d_short_seq.pgf}
    \end{adjustbox}
    \caption{Sequential threshold fitting.}
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \begin{adjustbox}{Clip=0 1em 0 0}
    \input{pgfplots/threshold_ufbb_toric_2d_comp.pgf}
    \end{adjustbox}
    \caption{Comparison.}
  \end{subfigure}
  \caption{Monte Carlo simulations for the decoding success rate using the Union-Find Balanced-Bloom decoder (Algorithm \ref{algo:ufbb}) on a toric code with independent noise.}
  \label{fig:thres_ufbb_toric_2d}
\end{figure}

\begin{figure}[htbp]
  \centering
  % \begin{subfigure}[b]{\textwidth}
  %   \begin{adjustbox}{Clip=0 1em 0 0}
  %   \input{pgfplots/threshold_ufbb_toric_2d_full.pgf}
  %   \end{adjustbox}
  %   \caption{All simulations.}
  % \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \begin{adjustbox}{Clip=0 1em 0 0}
      \input{pgfplots/threshold_ufbb_toric_2d_fb04.pgf}
    \end{adjustbox}
    \caption{Simulations $f_{bloom}=0.4$}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \begin{adjustbox}{Clip=0 1em 0 0}
      \input{pgfplots/threshold_ufbb_toric_2d_fb05.pgf}
    \end{adjustbox}
    \caption{Simulations $f_{bloom}=0.5$}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \begin{adjustbox}{Clip=0 1em 0 0}
      \input{pgfplots/threshold_ufbb_toric_2d_fb06.pgf}
    \end{adjustbox}
    \caption{Simulations $f_{bloom}=0.6$}
  \end{subfigure}

  \begin{subfigure}[b]{0.32\textwidth}
    \begin{adjustbox}{Clip=0 1em 0 0}
      \input{pgfplots/threshold_ufbb_toric_2d_fb04_seq.pgf}
    \end{adjustbox}
    \caption{Sequential fit $f_{bloom}=0.4$}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \begin{adjustbox}{Clip=0 1em 0 0}
      \input{pgfplots/threshold_ufbb_toric_2d_fb05_seq.pgf}
    \end{adjustbox}
    \caption{Sequential fit $f_{bloom}=0.5$}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \begin{adjustbox}{Clip=0 1em 0 0}
      \input{pgfplots/threshold_ufbb_toric_2d_fb06_seq.pgf}
    \end{adjustbox}
    \caption{Sequential fit $f_{bloom}=0.6$}
  \end{subfigure}

  \caption{Monte Carlo simulations for the decoding success rate using the Union-Find Balanced-Bloom decoder (Algorithm \ref{algo:ufbb}) on a toric code with independent noise.}
  \label{fig:thres_ufbb_toric_2d_fb}
\end{figure}
