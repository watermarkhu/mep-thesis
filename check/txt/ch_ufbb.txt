Union-Find Balanced-Bloom decoder

node=[circle, draw=black, minimum size=25pt, line width=1, inner sep= 5pt]
nodel=[circle, draw=black, minimum size=15pt, line width=1, inner sep= 0pt]
tnode=[nodel, minimum size=0.6 cm, fill=white]
node1=[circle, draw=black, minimum size=15pt, line width=1, inner sep= 2pt]
node2=[circle, draw=black, minimum size=8pt, line width=1, inner sep= 0pt, fill=white!70!black]
l1=[line width=1]
\tikzfading[name=fade right, left color=transparent!0, right color=transparent!100]
odd=[node1, dashed, pattern=dots, pattern color=mred!75!white]
even=[node1, pattern=dots, pattern color=mblue!75!white]
lodd=[odd, pattern = crosshatch dots]
leven=[even, pattern = crosshatch dots]
enset=[node1, thick, double, font=]
onset=[node1, thick, densely dashed, double, font=]
subtree=[node1, opacity=0.3,dotted, font=]


In this chapter we describe a modification of the Union-Find decoder, dubbed the Union-Find Balanced-Bloom decoder, that increases the code threshold of the Union-Find decoder by improving its heuristic for minimum-weight matching. We show that the modified decoder retains a relatively low time-complexity. 

Within the vanilla Union-Find decoder, not all odd-parity clusters are grown at the same time. Larger clusters relatively add more ``incorrect edges'' to themselves than compared to a smaller cluster (lemma X). The Union-Find decoder therefore applies weighted growth of clusters, where the order of cluster growth is sorted based on the cluster sizes. We have shown a linear-time implementation utilizing bucket sort in Section X. With the addition of weighted growth, the error threshold of the Union-Find decoder is reported to increase from X to X for a 2D toric lattice [0], whereas we measured an increase from X to X in our implementation of the decoder (Section X). Furthermore, we showed that by always maintaining a dynamic forest where all clusters are connected acyclic graphs (Section X), a slight increase in the code threshold and reduced running time can be obtained. 

From the simulated results of several of our implementations of the Union-Find decoder (Section X), we grew the intuition that a decreased weight is to some extent a heuristic for an increased code threshold (formalized in Proposition X). In fact, the instruction of the Union-Find decoder mostly tries to obtain a low weight matching; by growing the odd-parity clusters on their boundaries a single layer at the time, unions between odd-parity clusters mostly occur on nearest neighbors. The discrete coordinates of the lattice limits the number of growth iterations to a constant proportional to the lattice. But also due to this discreteness, there may be many unions within each growth iteration, and nearest-neighbor unions between clusters may not result in a minimum-weight matching between syndromes. Especially as the clusters increase in size, also does their boundaries, and an increasingly larger amount of ``incorrect edges'' are added to the cluster. Weighted grow reduces the number of large-cluster growths, but does not decrease the number of ``incorrect edges'' if a large cluster is grown. This leaves us with the question: Should all boundary edges of a cluster be grown simultaneously?

We suspect that the error threshold of the Union-Find decoder can be increased by improving the heuristic for minimum-weight matching. In this chapter, we accomplish this by sorting the growth of specific subsets of a cluster according to a parameter that we dub the potential matching weight, explained in X. We introduce a new data structure that we call the node-tree of a cluster in X. Within this node-tree, we compute the node-suspension and delay in X and X, which sets the order of boundary edge growth. In X through X, we cover the rules for growth and join operations for the node-trees, which are more complex than those of the Union-Find decoder. The modified decoder, the Union-Find Balanced-Bloom decoder, still has a relatively low worst-case quasilinear-time complexity, which is approximated in X. 

A potential matching weight

The Minimum-Weight Perfect Matching decoder finds the minimum-weight subset of edges by constructing a fully connected graph between all vertices (Section X). By computing on the entire lattice, we denote such decoder as a global decoder. The Union-Find decoder is a local decoder, as each cluster is grown individually, oblivious about its surrounding neighbors until it merges into them. We introduce in this section the concept of a potential matching weight of an odd-parity cluster, and we show that its value is not constant across the vertices of a cluster. Recall from Definition X that a cluster with index i is defined as an object X with an edge set X and vertex-tree X.

definition
  Consider an odd-parity cluster X containing a vertex v. The Potential Matching Weight (PMW) of the vertex v is the matching weight in the subset of edges of an odd-parity cluster X in a hypothetical union with another cluster X in the next growth iteration, where the merging boundary edge is supported by v. 
  In other words, the potential matching weight is a vertex-specific predictive heuristic to the matching weight assuming a union in the next growth iteration. 
definition

Note that the potential matching weight is thus not defined for a vertex that is not in the boundary of a cluster. Let us first consider an example. Cluster X is defined by vertex-tree X, where each vertex is a syndrome-vertex X (Figure X). The vertices lie on a horizontal line, distance 1 from each other, where each vertex has grown a single iteration of half-edges. The cluster has odd parity and is queued for growth. Let us investigate the weights of a matching if an additional vertex X is connected to the cluster. If X is connected to X or to X, then the resulting matching have a total weight of 2: X or X, respectively. However, if X is connected to vertex X, then the total weight is 3: X, where X has weight 2. 

From the above example, we can see that even for a minimal size odd cluster that is not a single vertex, the potential matching weight is not equal for all vertices in the cluster. It would therefore not be optimal to grow all boundary edges simultaneously, as boundaries connected to vertices with a high PNW potentially result in a higher matching weight. The growth these high PMV boundaries should thus be delayed for some iterations. When the PMV across the cluster reach an equilibrium, there is no benefit of growing some boundaries before others, and simultaneous growth is allowed again.



However, the calculation of the potential matching weight is seemingly not as straight forward, especially for clusters if increasingly larger size. Furthermore, if the potential matching weight is to be calculated for every vertex with boundary edges in all clusters in every growth iteration, the time complexity of the algorithm would increase dramatically. Luckily, we can reduce these calculations to be performed on a set of nodes in each cluster, which we clarify in the next section.

Node-tree data structure of clusters

To efficiently calculate the potential matching weights in a cluster, we introduce here an additional data structure, the node-tree of a cluster, that coexists with the Union-Find data structure. We consider the case of independent noise, after syndrome identification, all identified clusters consist of a single syndrome-vertex X. Note that with erasure noise, the initial identified clusters may be of larger size, where each connected graph of erased edges belonging to the same cluster. This set of clusters is equivalent to the syndrome set X. Within syndrome validation, these clusters are subjected to growth and merge events with other clusters. During growth, all vertices that are added to some cluster X have some closest syndrome vertex X within X that is in the syndrome set X, if a dynamic tree of the cluster is maintained. Recall from section X that a such a cluster is always a connected acyclic graph. Even after cluster merges, newly added vertices have some closely located syndrome-vertex. The growth of a cluster can thus be interpreted to be seeded in the syndrome vertices X, thus the growth of a single cluster containing multiple syndrome vertices is related to multiple seeded growths. 

theorem
  All vertices in the subset of boundary vertices seeded in the same syndrome-vertex X have the same potential matching weight, if a dynamic forest is maintained. 
theorem
proof
  All vertices X of an odd-parity cluster X have the same syndrome-vertex X located a minimum distance X on a path supported by edges in X. As a growth iterations means to grow all boundaries, all distances X have the same value. A hypothetical matching X with another odd-parity cluster on vertex X must contain edges X, since X is a tree. Furthermore, X is independent of which vertex X as long as they have the same seed. Thus, the potential matching weight
proof

definition
  Let a node X represent a subset of vertices of a cluster for which each vertex is seeded in the same seed vertex X, which is denoted as X in object notation. 
definition

definition
  Let a cluster X also be represented by a node-set X, stored as a tree by its root node at the cluster X. The subset of X containing vertices in the boundary X is denoted X, where X. Let the combined set of all nodes on a graph be denoted as X.
definition

Per Theorem X and Definition X, all boundary vertices of a node have the same potential matching weight. The calculation of the potential matching weights within a cluster can thus be limited to its node-tree X. From our previous example, each vertex in cluster X is a syndrome-vertex. For each of the vertices, their seed syndrome vertices are themselves. The node-tree is thus X where X, X and X. As this cluster grows in size, the number of vertices in X increases in each round, while the number of nodes in X remains the same at 3 nodes (Figure X). The node-tree is thus a reduced tree of cluster X where each node contains a subset of vertices in X and each edge of the reduced tree is equivalent to one or more edges in X. Furthermore, as every node needs to be seeded in some vertex, the number of nodes X is limited by the number of vertices on the lattice. 


Node types

There are various types of nodes that behave slightly differently. In this section, we introduce the syndrome-node and the linking-node, which are required for decoding on a toric code. For bounded surfaces such as the planar code, the boundary-node is required additionally, which is covered in Section X. 

definition
  Let a syndrome-node X denote a node that is seeded in a syndrome-vertex. 
definition

The node type that we have described in the previous section is a syndrome-node. Boundary vertices X of a syndrome-node have a single seed syndrome-vertex for which there exists a minimum distance X as stated in the proof of Theorem X. This is true if all syndrome vertices are located an odd distance from each other. But this is not the case at all as the distance between syndrome vertices is only limited by the discrete nature of the lattice and the size and boundary (if it exists) of the lattice itself. For two syndrome vertices X located an even distance from each other, each seeds a syndrome-node X, there exists some vertex X that lie in equal distance to both syndromes. If the clusters of X grow and reach vertex X in the same growth iterations, it is not clear to which syndrome-node X belongs, or which vertex X or X seeds X. 

definition
  Let a linking-node X denote a node that is seeded in a vertex that lies in equal distance to two or more seeds of other nodes. 
definition

This problem is solved by initiating a linking-node l with the vertex X as its seed. By doing so, every boundary vertex of the nodes X and X is limited to have a single nearest syndrome-vertex, which are X and X, respectively. For the linking-node, every boundary vertex in X is limited to have a single nearest linking-vertex X, which is its seed. We can replace every instance of X in Theorem X and its proof with X to see that the theorem also holds for linking-nodes. Thus, a linking-node also has the property that its boundary vertex set X has the same potential matching weight. Note that a linking-node initiated on a vertex that lies in equal distance to the seeds of any node, thus including other linking-nodes. 

Consider our example cluster X of 3 nodes X again. Now we slightly alter this cluster by increasing the distance between the seeds X and X to two edges. This means that cluster X is only established after two growth iterations of the three previous separate cluster of node-trees X, and has a total size of 13 vertices (Figure X). Now consider the vertices X and X that lie between X and X, respectively. These are linking-vertices as they lie in equal distance to two seeds. Thus, in the node-tree of the merged cluster X, linking-nodes X and X are initiated. 




Balanced-bloom

The data structure of the node-tree can be utilized to delay the growth of boundaries with a high potential matching weight, or prioritize the growth of boundaries with a low potential matching weight, as the boundaries confined in each node have the same potential matching weight per Theorem X. In order to do so, the growth of a cluster must be separated for the nodes in its node-tree. 

definition
  Let the bloom of a node n refer to the growth of the boundaries X. The growth for all boundaries of a cluster $
  \delta\vset_jX\nset_jXnnradius$ be the number of iterations it has bloomed. 
definition

In the search of a minimal weight matching, the growth of a cluster can thus prioritize the bloom of nodes with the lowest potential matching weight, and delay the bloom of nodes with larger potential matching weight. As these prioritized nodes bloom and increase in radius, the cluster moves towards equal potential matching weight across all nodes, where in each iteration the number of delayed nodes decreases. Once the equilibrium is reached, no nodes are delayed.
definition
  Balanced-bloom is the state of growth of an odd-parity cluster X when all nodes in its node-tree X have the same potential matching weight, and thus all nodes in X are bloomed. This state can be reached by prioritizing the growth of nodes with the lowest potential matching weight. 
definition
lemma
  Between union events, the potential matching weight of nodes in a cluster need only to be calculated once. The delayed node can be queued for some iterations based on the difference of its own potential matching wight and the minimal potential matching weight in the cluster.
lemma
proof
  While no unions between clusters occur, the cluster will be defined by the same set of nodes. The potential matching weight of nodes in the cluster is then defined by a potential matching X (Theorem X). The changes to the potential matching weight of a node X due to the growth of the cluster, or some iterations of bloom, is directly related to its radius X. As we can store the radius as an attribute of the node, the altered potential matching weight is then simply an X calculation involving its old value and X. 
proof

To finalize, the node-tree X of a cluster X is a reduced tree of the graph formed by X and X, and is thus also a connected acyclic graph. The node-tree is stored by its root node X at the cluster X. As node-trees merge and linking-nodes are initiated, children nodes added to the set by connecting them to the parent nodes by undirected edges. This is different from X which utilizes the Union-Find data structure (Section X), which has directed edges that point to the root. We will see in the next section why this is the case. 






Node parity and delay
The node-tree data structure allows for a reduction in the calculation of the potential matching weight, as the value for boundary vertices within the node are equal. However, if this calculation is done naively by calculating the potential matching weight for each node individually, where in each calculation the entire node-tree is traversed, the full calculation runs in quadratic time. Luckily, as we will explore in this section, the node-tree data structure allows us to calculate several values that relate closely to the potential matching weight; the node-suspension and node delay, by two depth-first searches from the root node. 

definition
  Let the node delay X be the difference in the number of bloom delay iterations of a node n and the root node X in the node-tree of an odd-parity cluster.
definition

definition
  Let the node-suspension X be an indicator for whether a node X has a larger delay compared to its parent in an odd-parity cluster; for even parity X then X, and for odd parity X then X. Even nodes are relatively prioritized and odd nodes are relatively delayed.
definition

theorem
  The node-suspension of a node X is only dependent on its own attributes and its children X:
  The node delay of a node X is only dependent on its own attributes and its parent X:
  multline
    s_\beta.d = s_\alpha.d + \Bigg \lceil k_eq \Bigg( 2\bigg(\fracs_\beta.r{2} - \fracs_\alpha.r + s_\beta.r \bmod 2{2} - (-1)^s_\beta.p(s_\beta,s_\alpha)\bigg)
    \Bigg) - 
    (s_\beta.r - s_\alpha.r) \bmod 2 \Bigg \rceil 
  multline
  where n.r denotes the node radius (Definition X) and X is an optimization parameter.
theorem
proof
  Equation X is proven by Lemmas X and X. 
proof

We will prove Theorem X throughout the following sections. In Section X, we introduce the concept of node delays and parities on syndrome-nodes through an example of a one-dimensional node-tree. In Section X, the same concept is applied to realistic node-trees, which is the dimension of the surface code that applies to realistic node-trees. These concepts are extended to linking-nodes in Section X. In Section X, we introduce the concept of the equilibrium-state of a node-tree that optimizes the minimal weight behavior through the X parameter. Finally, the pseudo-codes for the calculation of node delays are listed in Section X.

One-dimensional node-tree parity and delay

We introduce the concepts of node-suspension and node delay from Definitions X and X through a one-dimensional node-tree X of exclusively syndrome-nodes. In this simplification, all nodes lie on a horizontal line from X to X (Figure X). Let us calculate the potential matching weights for the nodes in this cluster. Recall from Definition X that the radius of the node s.r is equal to number of bloom iterations, one half-edge on the boundaries per iteration. This means that if a merge with some other cluster occurs on a boundary edge of s, the weight of the matching edges within the node s is equal to X or. For a merge on X, the matching weight X is the sum of X, the length of edges X, and some value k corresponding to the weight of matching edges in the remainder of the cluster. This calculation can be continued for other nodes:
The difference in the potential matching weight of a node X and its parent X has a more constant definition that is only dependent on the radii of X,  X, and the length of the edge connecting the two:

There is a trend in which contribution of the edge length the difference in the potential matching weight is dependent on the parity of the node number i. The difference X for some integer i has the positive addition of X, whereas the difference X has the subtraction of X. Thus, we can generalize the difference as

lemma
  The difference in delay between a node X and its parent X is related to the difference in potential matching weight by 
  where X is a repair function accounts for the degeneracy of the potential matching weight with
lemma
proof
  As the boundary edges grow only a half-edge per bloom, the difference in the node delays between a node X and its parent X is thus twice the difference in their potential matching weights. But also due to this discrete multiplication factor of 2 between the delay and the potential matching weight, there is a degeneracy when calculating the potential matching weights from the node radii. For example, the radii X for some integer k yields the same potential matching weight as X, X.

  The degeneracy between the node radius X and the parent node radius X exists only if the difference between the radii is odd. This is due to the division by 2 and the subsequent floor function. Thus, the degeneracy repair function X acts only when X is 1. 
  
  Disregarding the length of edges between two subsequent nodes, for nodes X with radii X, node X is thus larger and should have delay X compared with node X. For radii X, node X should have delay X compared with node X. This can be simplified with
  
  Furthermore, we find that the degeneracy is caused by a non-linearity in the difference of the potential matching weights:
   The non-linearity can be accounted for by combining Equation X with the condition of Equation X to obtain the repair function of X, which proves the lemma. 
proof

Combining Equations X and X, we find that the delay of a node is defined as
multline
  s_i.d = s_i-1.d + 2\bigg(\fracs_i.r{2} - \fracs_i-1.r{2} + (-1)^i(s_i,s_i-1)\bigg) + 
  (s_i.r - s_i-1.r) \bmod 2 \cdot \left(s_i.r - s_i-1.r{s_i.r - s_i-1.r}\right) \cdot (-1)^\left(s_i.r+s_i-1.r-1{2\right)\bmod 2 
multline
which can be further simplified to 
multline
  s_i.d = s_i-1.d + 2\Bigg(\fracs_i.r{2} - \fracs_i-1.r + s_i.r \bmod 2{2} + (-1)^i(s_i,s_i-1)\Bigg) - 
  (s_i.r - s_i-1.r) \bmod 2 
multline
where the repair function X has been partially moved into the main part of the function. We will not provide a description of this simplification, but Equation X has the exact same output as Equation X. 

Using equation X, we can calculate all the node delays in the one-dimensional node-tree by setting some initial delay for X, for example X. This is why the node delay is defined as the difference in the bloom delay iterations between a node and the root node, which is X in the one-dimensional node-tree. The node delay can thus also take negative values, as the choice for X is arbitrary. The absolute delay, the number of iterations for a node to wait, can then be calculated by subtracting the minimum delay in the node-tree X. Not to mention, as the potential matching weight does not change between union events (Lemma X), the node delays do not have to be recalculated in every iteration. This means that it is necessary to additionally to the number of iterations a node has waited.
definition
  Let X denote the number of bloom iterations a node n has already waited, then the absolute delay X of a node n in a cluster X with node-tree X is the actual number of blooms to wait at any given moment. The absolute delay is calculated with
  where X is the minimal delay value in the cluster
definition
Note that in Definition X, the general node element n is used instead of the syndrome-node s. This definition also holds for other types of nodes, such as linking-nodes (Section X) or boundary-nodes (Section X). The balanced-bloom state (Definition X) is thus reached when X for all nodes in the node-tree. 

Realistic node-tree parity and delay

The one-dimensional node-tree from the previous section does not accurately represent node-trees that occupy a real lattice. On a two-dimensional lattice (independent noise) and a three-dimensional lattice (phenomenological noise), the node-tree X is allowed to form in the same dimensions as an acyclic graph, instead of a linear set with index number i. The delay calculation on an entire node tree is not a sequence of calculations from node X to X, but a depth-first search from the root node X. Just as the previous section, we assume that X has excursively syndrome-nodes. Using the same strategy as in the previous section, we find that the equation for calculating the node delays is quite similar. The delay calculation is performed on a node X comparatively with the parent node X, which means that there must be some directed path within X, such that there is a clear direction, and the calculation is started from the root node s.r by setting X.

The edge contribution to the node-suspension X, whose sign was previously determined by the node index i, is now set by the node-suspension (Definition X). 
lemma
  For a node-tree of exclusively syndrome-nodes, the concept of the node-suspension can be defined as the number of descendant nodes modulo 2 (see Figure X). It can be calculated without counting the number of descendants for every node by using the recursive relation where the parity of a node X is only dependent on the parities of its immediate children X:
lemma
proof
  For a node X with a set of children nodes X, the node-suspension X can only be even if it has an even number of children nodes with even parity X, and an even number of children nodes with odd parity X. This is accomplished by Equation X. 
proof
Note that this definition of the node-suspension is identical as in a one-dimensional syndrome-node-tree, where a node with an odd index effectively has an even number of descendant nodes and results in a contribution X, and an even indexed node results in a contribution X. The parity calculation thus requires the parity of every child node to be known, which means that the parity calculation of X is related to a depth-first search from the root node X, with a tail-recursive function to calculate the parities from the bottom up. To calculate the node delays within X, a second depth-first search is applied with
multline
  s_\beta.d = s_\alpha.d + 2\Bigg(\fracs_\beta.r{2} - \fracs_\alpha.r + s_\beta.r \bmod 2{2} - (-1)^s_\beta.p(s_\beta,s_\alpha)\Bigg) - 
  (s_\beta.r - s_\alpha.r) \bmod 2 
multline
where X is the node of interest and X is a parent of X, and the sign of the edge component is now dependent on the node-suspension s.p.



Linking-node-suspension and delay

Up until now, the existence of linking-nodes has been neglected in the node-suspension and delays calculations. In this section, we will extend upon the previous equations for node-suspension and delay to include linking-nodes. Luckily, the delay calculation of Equation X still holds for linking-nodes. However, the parity of a linking-node is calculated differently. Consider an example node-tree X with 5 syndrome-nodes X lined up linearly with distance 1 between them and X (Figure Xa). Let us consider a delay X from Equation X but leaving out the node radius components as we are now only interested in the parity component X. The parity of X is odd, therefore



Consider now a second example node-tree X with 3 syndrome-nodes and 2 linking-nodes X (Figure Xb). Recall that a linking-node does not have a syndrome-vertex as seed, and thus matching must occur between seeds of the syndrome-nodes. The potential matching weights without the radius component X in X are
and the delays in X are 

lemma
  The parity equation X can be altered to apply for both syndrome-nodes and linking-nodes by   
lemma
proof
  The node parities of subsequent syndrome-nodes in a node tree should be independent on the number of intermediate linking-nodes, as the matching only occur between the syndrome-vertex seeds of the syndrome-nodes. The parities of the intermediate linking-nodes should thus satisfy this requirement. By applying 1 minus the definition for the parity of a syndrome-node, the parity of the nearest descendant syndrome-node is effectively passed on to the linking-node, such that the parity flip only occurs at the next syndrome-node when moving upwards in the node-tree. 
proof


Node tree ancestry


Recall from the last paragraph of Section X that the edges of the node tree are undirected. However, the depth-first searches to calculate the node parities and delays clearly indicates that there is some ancestry in the node tree. In this section, we will clarify this feature of the node-tree. 
lemma
  Any node X is a valid root. The root X, which has parity X, determines the node parities within the node-tree. 
lemma
proof
  Since the node parities are calculated from the descendants to the root, and the node delays are subjected to an arbitrarily chosen delay for the root X, any node in X can be chosen as the root. Recall from Definition X that the node-suspension is only defined for an odd-parity cluster. For a node-tree of exclusively syndrome-nodes, this means that X must have an even number of descendant nodes, and thus per Lemma X it must be that X. From a node-tree of mixed syndrome-nodes and linking-nodes, recall from Lemma X that linking-nodes always copies the parity of the nearest descendant syndrome-node, thus X. Choosing which node X is the root node X for this reason determines the parities in the node-tree (see Figure X). 
proof

The node-tree has undirected edges, such that it is not set in stone which node is the root. When to clusters merge into one, their respective node trees need to be merged too. As the edges in the node-tree reflect one or many physical edges on the lattice, the merge of node-trees can not be applied by simply pointing one root to another, such as in the Union-Find data structure. In stead, the node-trees X are joined on the nodes X containing the boundary vertices that support the newly grown edge that links the clusters. This can be done by setting one of the nodes X or X as the subroot if its tree and connecting it with the other. This motivates the use of undirected edges. New roots can be chosen that allows for the union of node-trees. More on the union of node-trees is described in Section X. 

lemma
  The calculated node delays X are only valid while node parities have been calculated with the same root node X. The absolute delay X is independent on the selected root node. 
lemma
proof
  Since both the calculation of the node parities and node delays are performed by a depth-first search of the node tree, and the node parities are dependent on which node is set as root (Lemma X), it is trivial that the node delay calculation should follow the same depth-first search as the parity calculation. The absolute delay X is independent on root node as it is the node delay X minus the minimal delay in the cluster c.d (Definition X). Recall that the node delay value the difference with X, whose value is arbitrary. By subtracting the minimal delay value in the cluster, this arbitrariness is accounted for. 
proof



Equilibrium optimization

In this section, we alter the delay equation X with an extra parameter X to optimize a trade-off in this algorithm. This trade-off occurs in about X of the node-tree unions in an event that we dub parity-inversion. Recall from Lemma X that after a union, the potential matching weight within the node-tree changes, and the parities and delays may have to be recalculated. Note that we will describe in Section X necessary steps to actually grow a cluster with the node-tree data structure, and in Section X we describe how to actually merge node-trees. In this section, the focus is on what happens to the potential matching weight and the subsequent required recalculation of the node parities and delays. 

When clusters grow in size, their nodes are delayed such that the equilibrium in the potential matching weight can be reached. Because of this, the prioritized nodes have larger radii than the delayed nodes. As clusters merge, their node-trees are also joined on the nodes that contain the vertices supporting the connecting edge. Due to the merges, the parities of nodes in parts of the joined node-tree may flip, which we dub parity inversions. This means that the previously prioritized nodes become the nodes to be delayed, and the previously delayed nodes are to be prioritized. As these nodes have already grown in different radii, the parity inversion causes that after the flip in priority, it takes twice as many iterations to reach the equilibrium in potential matching weight. As more and more unions occur, the number of parity inversions increases and so does the number of iterations needed to reach equilibrium. 

definition
  The equilibrium-state X of cluster describes the degree of potential matching weight equilibrium in the cluster with node-tree X, where M is the number of iterations with delayed blooms needed to reach equal potential matching weight, and X is the number of iterations grown while equal potential matching weight has not been reached (Figure X). The X equilibrium-state is maximally occupied when all nodes in the node-tree have equal potential matching weights, and is thus equivalent to the balanced-bloom state of Definition X. 
definition
For example, a cluster with X requires 4 growth iterations to reach an equilibrium in potential matching weight in all nodes in the cluster. The equilibrium-state thus gives us an indication of how near balanced-bloom a cluster performs. 
lemma
  Let X denote the equilibrium-state of a cluster just before a union with another cluster that causes a parity inversion, and X the equilibrium-state after union, then X.
lemma
proof
  In the context of the equilibrium-state, the delayed bloom of nodes in cluster growth is equivalent to increasing the value of I in the equilibrium-state. As X, the difference between the radii of the prioritized and delayed nodes increases, thus also increases the iterations X needed after the union and parity inversion. 
proof
Subsequent parity inversions cause a gradual but certain increase in M of the equilibrium-state, depending on X during the parity inversion at the union, requiring a growing number of growth iterations X to reach the equilibrium-state X. As the lattice size is increased, the total number of unions of a cluster with other clusters also increases, leading to a growing number of parity inversions. Thus increasing the lattice size has the consequence that more growth iterations I are needed to reach equilibrium-state X. This is the trade-off in the effectiveness of this algorithm. On the one hand, it is preferred that X to maximally occupy the equilibrium-state that is a heuristic for minimum-weight, but on the other, I is also proportional to the number of iterations needed to actually reach X due to parity inversions. 

definition
  Let the equilibrium factor X be a target factor to the node delay. 
definition
lemma
  The delay equation where the delays have a factor X minimizes the trade-off caused by parity inversion. 
  multline
    s_\beta.d = s_\alpha.d + \Bigg \lceil k_eq \Bigg( 2\bigg(\fracs_\beta.r{2} - \fracs_\alpha.r + s_\beta.r \bmod 2{2} - (-1)^s_\beta.p(s_\beta,s_\alpha)\bigg)
    \Bigg) - 
    (s_\beta.r - s_\alpha.r) \bmod 2 \Bigg \rceil 
  multline
lemma
proof
  For any X, a cluster will never actually reach the X equilibrium-state, but only X. Let the equilibrium-state with the equilibrium-state be thus be defined as X. Consequently, after a parity inversion, the difference in node radii between prioritized and delayed nodes is decreased, such X can be reached in a lower amount of growth iterations. 
proof

In Figure X and X a comparison is made between the growth of a set of node-trees using Equation X with X (same as Equation X) and with X. We see that the number of iterations needed to maximally occupy the equilibrium state using X is halved both before and after the union with parity inversion when using X. 

The optimal value of X may be dependent on the number of parity inversions, and consequently the lattice size, growth iteration, and the node-tree and cluster sizes X, with the goal of maximally occupying the equilibrium-state after the last parity inversion. We suspect that due to the fact that M doubles after parity inversion, a constant factor of X should behave well on average, as the equilibrium state is occupied half on average. However, other values of X should be explored and optimizations dependent on these variables could be possible. 


 
Parity and delay calculations

With equation X and X, we now finally have the tools to formulate the algorithms to calculate the node parities and delays. For a node-tree with root X, we can calculate the parities by calling the head recursive function Calcparity on X in Algorithm X, where we do a reverse DFS of the node-tree. The node delays are calculated by calling the tail recursive function Calcdelay in Algorithm X, where we perform a second DFS of the node-tree. This parity and delay calculation will from this point sometimes be abbreviated as PDC. A schematic of the directions of these calculations in an example node-tree is included in Figure X.





Growing a cluster
With the knowledge of previous section, we now have the equations and algorithms available to describe the steps to grow a cluster in the context of Union-Find Balanced-Bloom. Previously, in the Union-Find decoder, a cluster is grown with X (Algorithm X). Here, the boundary edges connected to the vertices in X are grown by increasing the value of e.support. If X, e is added to the merging list X to merge the vertex-trees at some later moment. 

In the node-tree data structure, the growth of a cluster is equivalent to a depth-first search of the node-tree, which will now be performed by X (Algorithm X). The boundary list for each cluster is not stored at the cluster X, but separately stored at each of the nodes X in X by X. We travel to all X from the root X and apply X (Algorithm X), which grows the boundaries for each node individually. Again, if an edge on the boundary are grown to X, e is added to the merging list X to merge the vertex-trees and node-trees at some later moment. The merging of node-trees is considered in Section X. 

Recall from Theorem X that with Balanced-Bloom, the bloom of node with the lowest potential matching weight in the cluster are prioritized, whereas the bloom of other nodes are delayed. Also, from Lemma X, in the absence of unions the delays are not recalculated after every growth iteration, but stored in memory at the nodes. Definition X introduced the absolute delay X, where the actual number of iterations to delay is updated via the minimal delay value X in the cluster and the number of iterations already waited n.w. Thus, when performing the depth-first search in Ngrow, a node should be conditionally bloomed if only X is satisfied. If not, node X is skipped, the wait n.w is increased and search continues recursively on its children nodes. 




Joining node-trees
Within the vertex-tree X, which utilizes the Union-Find data structure, path compression and union by weight or union by rank are applied to minimize the depth of the tree and therefore minimizing the calls to the Find function. Similarly, in the node-tree X, we would also like to apply a set of rules to minimize the calls to Calcparity and Calcdelay, which we will dub the parity and delay calculation minimization.

definition
  A partial parity or partial delay calculation, which will often be abbreviated to a partial calculation, is one associated with a depth-first search that is not initiated from the root node X, but some descendant node of X in the node-tree. 
definition

This minimization is achieved by preserving the node parities and delays in subsets of the merged node-tree after union, and applying a partial calculation of the parities and delays in the remaining subsets if required. The recursiveness of both Calcparity and Calcdelay (Algorithms X and X) ensures that this is possible. The tail-recursive parity calculation stops at the node where the depth-first search is started, and the head-recursive delay calculation now has a non-arbitrarily node delay. 

With the addition of the node-tree data structure, during merge of clusters X and X, we have to additionally merge the node-trees X and X that requires its own set of rules that we will explain in this section. Let us first make a clear distinction between the various methods. For the merge of vertex-trees X we apply X (Algorithms X or X), with the two vertices spanning the edge connecting two clusters as arguments. For the merge of node-trees X, we introduce here X (Algorithm X), which is called on the two nodes X that seed vertices X, respectively. During a merge of two clusters, these routines are both applied on their respective sets. Within the context of the Union-Find Balanced-Bloom decoder, when either one of the expressions ``merge clusters X and X'', ``the union of vertex-trees X and X'' or the ``join of node-trees X and X'' is mentioned, it is always implied that both routines are executed.

definition
  Let the parity of a node-tree be the number of syndrome-nodes in the node-tree modulo 2. The parity of the node-tree is thus equivalent to the parity of its cluster. 
definition
definition
  Let us categorize the joins of two node-trees into two types: even-joins and odd-joins, depending on the parity of the node-tree after the join. An even-join may be the result of the join of two even node-trees or two odd node-trees, whereas an odd-join is the result of the join of one odd node-tree and one even node-tree.
definition


lemma
  If node-trees merge into an even node-tree X, all node parities and delays within X become invalid or undefined. 
lemma
proof
  Recall from Definitions X and X that the node-suspension and delay are only defined for odd-parity clusters. An even-parity cluster does not have a potential matching weight, as the matching within the cluster are already defined. However, X merge with another odd-parity cluster with node-tree X in a larger odd-join. In that case, we might think about ``reusing'' some node parities and delays that were already calculated in X. To reuse prior calculated parities and delays, a depth-first search on X is needed to find which sections are still valid, and which sections are not. This is especially the case when the clusters in the E-join are the results of joins within the same growth iteration. Checking the validity to reuse prior parities and delays then acquires the same complexity as redoing the calculation of parity and delays over the subtree X. Hence, the node parities and delays in the joined set after an E-join are undefined.
proof

lemma
  Consider an odd-join on nodes X, belonging to an even and an odd node-tree, respectively. Parity and delay calculations are minimized during if the node-trees are always joined by setting X as the child of X. 
lemma
proof
  If X is made a child of X, X is the new subroot of subtree X, and an even number of syndrome-nodes are now descendants of X, and parities within X and its root are unchanged. Recall from Lemma X that thus the delays in X are also unchanged. A partial parity and delay calculation can now be initiated from X and is proportional to X (Figure Xb). If X is made a child of X, an odd number of syndrome-nodes are descendants of X and changes the parities in the ancestors of X up to the root of the joined tree. The parities and delays now need to be recalculated in the entire tree, which is proportional to X (Figure Xc). 
proof






From Lemmas X and X, we can define a simple rule that determines how node-trees are joined.

definition
  Let the join by parity rule govern how to join node-trees in the event of clusters merging. For even-joins between two even or two odd node-trees, the parent and child node-trees can be picked at random. For odd-joins between nodes X, always make the even node-tree a child of the even node-tree, where X is now the subroot of the subtree X.
definition
The join by parity rule ensures that the parities and delays in X are preserved and that only a partial calculation is needed equivalent to the depth-first search from node X. Note the concept of a partial calculation is rather redundant. Using these rules for the joins of node-trees, the parity and delay calculations are never calculated on a full node-tree except for the initial round. 

Recall from Definition X that the node-tree X of cluster X is stored by its root node at X, which sets the ancestry in the node-tree. In a join of two node-sets, the join by parity rule requires to conditionally set the ancestry in the joined node-set. This can simply done by connecting the node-trees with a new edge selecting the correct root node to be stored the merged cluster (see Algorithm X). Also, due to the use of undirected edges, it is required to store the direction of the partial parity and delay calculation.

definition
  Let us make a distinction between the final odd-join between an odd node-tree X and an even node tree X to a joined node-tree X, and all others odd-joins that joined to X within the same round which we dub intermediate odd-joins. 
definition

lemma
  Redundant partial parity and delay calculations over even subtrees in intermediate odd-joins are prevented by applying the calculation directly before the growth of the cluster. 
lemma
proof
  Consider the case when partial delay and parity calculations are initiated from a node X directly after the join of X and X to the joined node-tree X while applying the join by parity rule of Definition X. If there are many odd-joins (and even-joins) within the same round of growth, that at the end of round all joins to a single cluster with node-tree X, every odd-join will require the partial calculation over the even subtree. There may thus be many even subtrees where multiple partial calculations are performed within the same round before the final cluster X is constructed. All but the final calculation will lead to the correct parities and delays in X. To circumvent any redundant calculations on the even subtrees of intermediate odd-joins, the partial calculation is suspended as much as possible, until just before a cluster is grown.
proof

Consider an example with 5 odd node-trees X (Figure X) that join to a single node-tree, where the partial calculation is applied directly after each join. The join of X and X to X is an even-join and requires no partial calculation. The join of X and X is an odd-join, and we apply partial calculations in X. The join of X and X is an even-join and the join of X and X is an odd-join, with partial calculations in X. The earlier computation in X is thus redundant. 



The only task now is to store the subroot of the even subtree X of the final odd-join, as this subroot is the starting point of the depth-first searches of the partial parity and delay calculation. For every odd-join between odd node-tree X and even node-tree X on nodes X to a cluster X, store the subroot X at the cluster as the undefined node subroot X (Algorithm X). If X is selected for growth and it has an undefined node subroot X, we apply X and X (Algorithms X, X) to calculate parities and delays in undefined subtrees. We then call X (Algorithm X) to grow the cluster. 




Pseudo-code
Now we have the full description of the alteration of the Union-Find decoder, which we dub the Union-Find Balanced-Bloom decoder. Recall from Theorem X that the potential matching weight is only defined if a dynamic forest of clusters is maintained, and Recall from Section X that weighted growth improves the code threshold of the Union-Find Decoder. Thus, the modification will be applied to the Dynamic-forest Bucket Union-Find decoder X. 

In the Union-Find Balanced-Bloom decoder of Algorithm X, partial parity and delay calculations are applied if a cluster X has an undefined node subroot X, and Grow (Algorithm X) is replaced with Ngrow (Algorithm X). Furthermore, when iterating over the edges of the merging list X, if the vertex-tree roots of the supporting vertices do not belong to the same cluster, it either means that a new vertex is added to the cluster, or that two clusters are merged. In the first case, the new vertex is added to the node, whereas in the second case, two node-trees are joined. To be able to differentiate between these cases, we need to additionally store the node n containing the vertex X at the vertex as v.n. With this data structure, two node-trees have to be joined on v.n and u.n if they both exist. Otherwise, the node is to be saved to the newly added vertex. 



Complexity of Balanced-Bloom

In this section, we will find the time complexity of the Union-Find Balanced-Bloom decoder (Algorithm X) through using an analytic approach. As the Union-Find Balanced-Bloom decoder is modification of the Dynamic-forest Bucket Union-Find decoder (Algorithm X), which is known to have a time complexity of X (Section X), we will only consider the added complexity that is made by the modification. The additional contribution to the complexity to the Dynamic-forest Bucket Union-Find decoder can be divided into two parts. First is the contribution by the depth-first searches of Calcparity and Calcdelay, the parity and delay calculations, which we dub the PDC complexity, treated in Section X. The second contribution will be caused the replacement of Grow with Ngrow, where now an additional depth-first search of the node-tree of every cluster needs to be performed to access its boundary edges stored at the nodes and grow them with Bloom. We call this second contribution the bloom complexity, which is detailed in Section X.

PDC complexity
Recall from Lemmas X and X that the node parities and delays within become undefined in the entire node-tree after an even-join, and that partial parity and delay calculations are to be performed in the even subtree after an odd-join. Lemma X proves that these calculations can be limited to the even subtrees in final odd-joins. The size of the even subtrees in these final odd-joins, multiplied by the number of final odd-join operations thus estimates the cost of the parity and delay calculations. 
definition
  Let X of Equation X be the total number of nodes traveled during depth-first searches of the parity and delay calculations.
definition

For every odd node-tree X, it may be the result by many joins of smaller ancestral node-trees in some previous growth iteration. Before X is grown, a partial calculation is performed on the even subtree X of the final odd-join of its ancestral node-trees. This calculation is related to two depth-first searches of the subtree from undefined node subroot X. The cost of the calculation is thus proportional to X, and counts towards X. Subtree X may itself be the result of many intermediate odd-joins and even-joins in some previous growth iteration. But as these joins do not add towards X, it is not crucial to know which joins have occurred. What matters to the X count is to know the entire set of odd subsets X that constructs X, as each of X is subjected to a partial calculation from their undefined node subroots or in their even subtrees when they are grown.

definition
  Let the fragmentation of a node-tree X split X into a set of its ancestral node-trees X, and resembles the inverse of a join operation. Here the prefix k indicates the ancestral generation, where a larger k is equivalent to a more distant ancestor set of smaller subtrees. As the size of the even node-tree in the final odd-join counts towards X, we make the distinction between partial fragmentations X and X. Partial fragmentation X on an odd node-tree is equivalent to the inverse of the final odd-join to node-tree X, where
  Partial fragmentation X on an even node-tree is equivalent to the combination of all intermediate odd-joins and even-joins that join to X, with
  where X is split into X odd ancestral subtrees within the same ancestral generation. Let X be the partial fragmentation number. Let us call the 2 fragmentations X of an odd node-treeX into a set of odd node-trees X a fragmentation step f. Note that a fragmentation step is only possible on a node-tree X with X, in which case the resulting subsets have size 1.
definition



If partial fragmentation function X is called on a set of node-trees X, it fragments all odd node-trees in the set, and X fragments all even node-trees. Along these lines, the entire set of odd node-trees X can undergo the another fragmentation step into odd subsets, resulting in a second set ancestral node-trees X. We can do this some p times on X, where we have set X, until our resulting set of node-trees X consists only of the smallest possible node subsets X where X. 

definition
  Let the series of all p fragmentation steps f on X be the full fragmentation F, with
definition

To find the worst-case complexity, we maximize X or the cost of the partial calculations during the construction the node-trees on the lattice. Let us assume the worst-case when there are a maximal number of nodes in the node-trees just before the last round of growth. As the lattice is maximally occupied, this is a single odd node-tree X in which a partial calculation is performed as part of the last round of growth. Node-tree X has a maximal number of nodes if X for all nodes n in X. Thus, on a lattice of X vertices, the node-tree X has a maximal 
nodes. As the partial calculation is only executed on the even subtrees, X is the sum of even node-trees sizes X, in all partial fragmentation sets X, during all fragmentation steps X, in the full fragmentation of X. We add the factor 2 in Equation X as both the parity calculation and delay calculations requires its own depth-first search. The sequence of fragmentations that maximizes the even node-tree sizes maximizes X.

definition
  Let the partial fragmentation ratio R be the relative sizes of an ancestral node-tree X and the fragmented node-tree X.
definition
In X there are a set of partial fragmentation ratios X, and in X are a set of partial fragmentation ratios X, where

The problem of finding the sequence of even ancestral node-tree sizes to maximize the value of X now becomes finding the partial fragmentation number X and the set of partial fragmentation ratios X.  

lemma
  For the same partial fragmentation ratios X in X, the sum of even ancestral node-tree sizes after a fragmentation step is not dependent on X (see Figure X). 
lemma
proof
  Let us consider an even node-tree X that is first partially fragmented by X to X. The fragmentation set X is then partially fragmented by X to X. Let us consider the two cases when X and X. For X, the partial fragmentation X splits X into two odd ancestral node-trees in X and four node-trees in X.
  The ratios of the sizes of fragmented node-trees in X are
  where X. The ratios of the sizes of fragmented node-trees in X are
  where X. The sum of the sizes of even node-trees in the odd partial fragmentation set X is thus

  For X, the partial fragmentation sets are
  The ratios of the sizes of fragmented node-trees in X are
  where X. The ratios of the sizes of fragmented node-trees in X are
  and 
  where X. The sum of the sizes of even node-trees in  the odd partial fragmentation set X is thus
  This is true for any X. 
proof

lemma
  The sum of even node-tree sizes in every fragmentation step k is only dependent on partial fragmentation ratios X. 
lemma
proof
  Consider an odd node-tree X that is partially fragmented as 

  The sum of even node-tree sizes in X is simply the size of X and is equal to

  The sum of even node-tree sizes in X can be divided into two parts. The first part is the partial fragmentations X of X, which we know from Lemma X is X regardless of the choice for X. The second part is the partial fragmentation X of X, which is X. Hence, the sum is
proof

theorem
  For the fragmentation number X, X of Definition X and Equation X is maximized (see Figure X). 
theorem
proof
  The sum of even node-tree sizes in each fragmentation step is constant per Lemma X. Thus, X is maximized by having as many fragmentations steps as possible, or the largest possible p.  As X increases the number of odd node-trees in each fragmentation step X, the average size of these odd node-trees have decreased. Consequently, the node-tree size decreases faster towards the minimum size of 3 nodes as more fragmentation steps are applied (Equation X). As the sum of even node-tree sizes in each fragmentation step is the same, increasing X decreases the number of fragmentation steps: 
   Hence, X is maximized for minimal value of X which is X.
proof



The search for the fragmentation ratios has now been reduced to finding X of X and X of X since X. A partial fragmentation X of X and fragmentation step f of X are now
The sizes of the ancestral odd node-trees in a fragmentation step f are related to the joined node-tree by
where

This fragmentation number does not come unexpected. If X, a fragmentation X outputs two ancestral node-trees. This is equivalent to a single even-join. If X, the fragmentation X will be equivalent to a number of even-joins and intermediate odd-joins. Recall from Lemma X that the partial calculation of every intermediate odd-join is skipped. Thus, these partial calculations are ``lost'' in the maximization of X. 

Let us now try to maximize X of Equation X not from the perspective of fragmentations, but from the perspective of cluster growth. During a growth iteration, some X vertices are added to the cluster X and some other clusters merge with X that also require the join of their respective node-trees. If no join operations occur, the node-tree stays unchanged, and the cluster is allowed to continue to grow without delay calculations per Lemma X. To maximize X, X must be minimized, as every added vertex here is one that could have been part of a node in some other node-tree, and thus does not add to X. 

theorem
  For the fragmentation ratios X, X of Definition X and Equation X is maximized in a Union-Find Balanced-Bloom decoder with weighted growth (see Section X). 
theorem
proof
  Take the partial fragmentation X of X of Equation X and X of Equation X, which are equivalent to a final odd-join between X and even-join between X, respectively. 
  
  For X that is equivalent to the even-join to even-parity cluster X between the odd-parity clusters X with node-trees X, the clusters must have relative equal vertex-tree sizes 
  If not, clusters X may be allowed to grow multiple iterations before merging, sorted by weighted growth. In each iteration some X vertices are added tot the cluster. Let the growth iteration in which the even-join occurred be labeled as X
  
  For X equivalent to the final odd-join between even X and odd X, the final odd-join must strictly occur after the even join of X. This odd-join can either be initiated by odd-parity X in some growth iteration X, when X is the only odd-parity cluster, or initiated by either X or X in growth iteration X (see Figure X). Determined by weighted growth, the vertex-tree sizes are related as
  Recall from equation X that X. We assume the largest possible node-tree size X to find that 
  and hence
  To maximize X, we want to maximize X or X. Since X, X must be as small as possible, and thus X. 
proof



The last unknown parameter for the maximization of X in Equation X is p, the total number of fragmentation steps. If we assume that in every growth step not a single non-node vertex is added X, the full fragmentation of odd node-tree X is just the continuous division of the set in 3 parts per Theorem X, which can be calculated easily.
In every partial fragmentation set X, the sum of even node-tree sizes is 
as X per Theorem X and this value is constant for every fragmentation step is constant per Lemma X. This is an inequality as we have assumed X and X in Theorem X. Filling in equation X and X in X, we find that

Recall from Equation X that the node-tree size of set is bounded by the lattice size X. The worst-case time complexity of the delay computation is thus bounded by X. The average-case complexity is even lower as it is quite certain that not all vertices are nodes such that X and X.

Bloom complexity

To grow a cluster represented by a node-tree X, a depth-first search is performed on the node-tree to iterate over each boundary list that are stored at the nodes. 
definition
  Let the total number of times nodes are bloomed with Bloom be X.
definition

Similar to the previous section we make the assumption of a maximum number of nodes on the lattice where in each cluster X and X. For a fragmentation step of X to X, X is maximized if all three ancestral node-trees are grown. As the growth of every set X adds X to X, the total number of bloom can be found similarly to X in Equation X. The sum is now on all odd node-tree sizes in all p fragmentation steps X: 
For a full fragmentation of X of size X, the sum of all set sizes in each fragmentation set X is
By filling in p from X, we find that
which again corresponds to a worst-case time complexity that is bounded by X.

Compatibility

In this section, we shortly describe how to alter the Union-Find Balanced-Bloom decoder of Algorithm X to be compatible with surface with boundaries such as the planar code (Section X), and erasure errors. 

Surfaces with boundaries
For surfaces with boundaries, we introduced the concept of open vertices X that in contrast to normal vertices are not equivalent to stabilizers, measurements or ancillary qubits (Section X). During formation of the spanning forest X of a cluster, we must make sure that X does not contain more than 1 element of the set of boundary vertices X, as multiple elements of X is equivalent to a cycle (Section X).
definition
  Let a boundary-node b denote a node that is seeded in an open-vertex X. 
definition
The addition of boundaries requires a new type of node element, the boundary node n, that is exclusive to boundary vertices of X, and are initiated on a boundary vertex if a cluster grows into the boundary. Recall from Section X that there can be only 1 boundary vertex in X. For this reason there can be only one boundary node in X. As a result, a boundary node will always be a trailing node in X with no children, and will never be the root node. However, the always-trailing boundary node  always has parity 1, as a matching with the boundary is equally valid as a matching with another syndrome. The addition of boundary nodes just requires a small alteration to Algorithm X.


For a surface containing N qubits, the number of boundary elements scales with X. The number of node elements is thus bounded by X. The added complexity due to the boundary elements will therefore not exceed some linear factor and remains the same as previously computed.

Erasure noise

The inspiration for the Union-Find decoder is the Peeling decoder (Section X), that only accounted for erasure errors. As the Union-Find Balanced-Bloom decoder is a modification of the Union-Find decoder, we naturally need to make sure that it can also solve erasure errors.

To account for these erasures, we must construct the node-trees for these initial erasure clusters. We can easily check that for an erasure-cluster, the potential matching for every neighboring vertex is different. Every vertex in the cluster is therefore a node in X, where each syndrome-vertex is a syndrome-node X, and every other vertex is a linking-node l. Note that if the erasure is connected to the boundary, we need to make sure that only a single edge is connected to the boundary, where the single boundary vertex in the cluster naturally is a boundary node b. After constructing these initial clusters and node-trees, we can proceed to the Union-Find Balanced Bloom decoder.  

Performance

We benchmark the performance of the Union-Find Balanced-Bloom decoder of Algorithm X using our own implementation in Python3 (see Appendix X). This is done by Monte Carlo simulations of decoding on a simulated lattice and to fit for the code threshold as described in Section X. For the independent noise model (Definition X), we simulate on lattice sizes X with a minimum of 96.000 samples and on X with a minimum of 28.800 samples. For the phenomenological noise model (Definition X), we simulate on lattice sizes X with a minimum of 105.600 samples and on lattice sizes X with 13.200 samples. The code thresholds for the toric and planar codes with independent and phenomenological noise are listed in Table X, which also includes thresholds of the Minimum Weight Perfect Matching (MWPM) decoder (Table X) and the Dynamic-forest Bucket Union-Find (DBUF) decoder (Table X) for comparison.

Threshold

We had initially simulated for the decoding success rates for the range of lattices in X, which is the same range used when benchmarking the various implementations of the Union-Find decoder in Section X. For X, we find that except for the environment of planar code with independent noise, the thresholds of the Union-Find Balanced-Bloom decoder are increased from the DBUF thresholds, and moves close to the thresholds of the MWPM decoder. Furthermore, we also observe an increase in decoding success rate at the threshold X from DBUF, which is also the case for the environment of planar code with independent noise. For the range of lattices in X (Figure X), the threshold of the Union-Find Balanced-Bloom decoder decreases to below DBUF thresholds. This does not necessarily mean that it performs worse, as X is still above DBUF's values, but does raise questions on the scalability of the Union-Find Balanced-Bloom decoder. In fact, if we look closely at the values of X (Figure X), we find that the fit does not accurately represent the underlying data points, which is a different behavior from the MWPM and DBUF decoders. The threshold and X of the Union-Find Balanced-Bloom decoder may not be accurate for a comparison. 

For this reason, we have applied a sequential fit to the data acquired in the Monte Carlo simulations of lattices of X. In the sequential fit, we iterate stepwise in the ordered list of lattices sizes L and fit for the data of X for X iterations. The fit thus returns an error threshold in the range of the chosen lattices sizes. The range of thresholds X for the environment of toric code with independent noise are plotted in Figure X. We see that the sequential fits follows a trend where the increase in the input lattices sizes results in a decrease in X but increase in X. The range of thresholds coordinates X are plotted in Figure X together with the data acquired from the simulations for the performance of the MWPM decoder and the DBUF decoder. Similar figures for the planar code with independent noise, both the toric and planar codes with phenomenological noise are included in Figures X, X and X. 

We ascribe the degradation of the threshold error rate to the parity inversion effect, explained in Section X. Recall from Lemma X that the number of iterations waited before a union X is proportional to the number of iterations required to reach the balanced-bloom state (Definition X) X, where X is the equilibrium state of Definition X. By setting the equilibrium factor to X, the equilibrium state is occupied half on average. The degradation is caused by the proportionality of the number of parity inversions and therefore M to the lattice size. As the lattice size increases, the equilibrium state is still occupied half on average, but the absolute difference in X increases. It is thus increasingly more unlikely that the balanced-bloom state is reached. 

Overall, the Union-Find Balanced-Bloom decoder has an increased error threshold X from the threshold of the Union-Find decoder for small lattice sizes, and is comparable to the threshold values of the Minimum-Weight Perfect Matching decoder. For larger lattice sizes, the error threshold decreases, but the Union-Find Balanced-Bloom decoder still has an increased performance, which is now defined by an increased decoding success rate at the threshold X. The improvement across all lattice sizes is most apparent when comparing the range of threshold coordinates in X space, where the coordinates now occupy a range that is not possible with the Union-Find decoder. 


Equilibrium factor

We explore other constant values of the equilibrium factor X in Equation X, which calculates the delay for the nodes in the Union-Find Balanced-Bloom decoder. We simulated on lattice sizes X for a minimal of 56.000 samples with X around the threshold error rate. The data is sequentially fitted and the threshold coordinates are plotted on axes with the same range for comparison in Figure X. 

From the Figure, we can conclude that for a constant value of the equilibrium factor, it is optimized for the best error threshold and decoding success rate at X. For both X and X, the set of threshold coordinates X are located under the curve of the set of threshold coordinates of X. This confirms our suspicion at the end of Section X, which is motivated by the fact the M doubles with every parity inversion. Again we would like to if the equilibrium state can be maximally occupied after the last parity inversion, the node-tree can move closer to the balanced-bloom state. Some function dependent on the node-tree may thus dynamically alter X to facilitate this. 


Matching weight and running time

Finally, we plot the average matching weight and running time of the Union-Find Balanced-Bloom UFBB compared with the Dynamic-forest Bucket Union-Find decoder (DBUF) and the Minimum-Weight Perfect Matching (MWPM) decoder for data acquired on simulations on a toric code with independent noise and X in Figure X. We can see from this figure that the Union-Find Balanced-Bloom decoder has a constant decreased weight. As for the running time, the UFBB decoder offers a midway choice between the MWPM decoder and DBUF decoder. For the same plots but on a planar code or phenomenological noise we refer to Figures X and X, for which we observe the same behavior. 

We find that the decrease in weight is constant across the range of values of X, which is also the case for the planar code, the phenomenological noise model. We can compare the decrease in matching weight as the ratios between the normalized matching weight between the UFBB and DBUF decoders as
We find the averaged values for X from the Monte Carlo simulations on the toric and planar lattices, and with the independent and phenomenological noise models in Table X. The Union-Find Balanced-Bloom decoder successfully decreases the matching weight from the Dynamic-forest Bucket Union-Find decoder. The decrease is more apparent in under the independent noise model. 


